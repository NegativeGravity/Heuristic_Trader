{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Dummy Data\n",
   "id": "e7f6c70450f58932"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — Stage 1: Generate consecutive OHLCV data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_consecutive_ohlcv(\n",
    "    periods,\n",
    "    start,\n",
    "    freq,\n",
    "    start_price,\n",
    "    drift_per_bar,   # mean log-return per bar (upward drift)\n",
    "    vol_per_bar,       # std of log-returns per bar (volatility)\n",
    "    wick_frac,          # wick size factor relative to body/volatility\n",
    "    vol_min, vol_max,\n",
    "    seed\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate a consecutive OHLCV DataFrame where open[t] == close[t-1].\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Time index\n",
    "    idx = pd.date_range(start, periods=periods, freq=freq)\n",
    "\n",
    "    # Price path via log-returns ~ N(drift, vol)\n",
    "    rets = rng.normal(loc=drift_per_bar, scale=vol_per_bar, size=periods)\n",
    "    close = start_price * np.exp(np.cumsum(rets))\n",
    "\n",
    "    # Consecutive opens\n",
    "    open_ = np.empty(periods, dtype=float)\n",
    "    open_[0] = start_price\n",
    "    open_[1:] = close[:-1]\n",
    "\n",
    "    # Wicks based on body and volatility\n",
    "    body = np.abs(close - open_)\n",
    "    wick_scale = wick_frac * (body + (vol_per_bar * 0.5 * close))\n",
    "    up_wick = rng.random(periods) * wick_scale\n",
    "    dn_wick = rng.random(periods) * wick_scale\n",
    "\n",
    "    high = np.maximum(open_, close) + up_wick\n",
    "    low  = np.minimum(open_, close) - dn_wick\n",
    "    low = np.clip(low, 1e-9, None)  # keep prices positive\n",
    "\n",
    "    # Integer volumes\n",
    "    volume = rng.integers(low=vol_min, high=vol_max, size=periods)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\"open\": open_, \"high\": high, \"low\": low, \"close\": close, \"volume\": volume},\n",
    "        index=idx\n",
    "    ).rename(columns=str.lower).sort_index()\n",
    "\n",
    "    # Sanity: ensure consecutiveness\n",
    "    assert np.allclose(df[\"open\"].iloc[1:].values, df[\"close\"].iloc[:-1].values), \\\n",
    "        \"Consecutiveness failed: open[t] must equal close[t-1].\"\n",
    "    return df\n",
    "\n",
    "# --- Build your OHLCV dataset (as requested) ---\n",
    "df = make_consecutive_ohlcv(\n",
    "    periods=5000,\n",
    "    start=\"2022-01-03 09:30\",\n",
    "    freq=\"5min\",\n",
    "    start_price=100000.0,\n",
    "    drift_per_bar=0.0005,\n",
    "    vol_per_bar=0.02,\n",
    "    wick_frac=0.5,\n",
    "    vol_min=100, vol_max=5000,\n",
    "    seed=None,\n",
    ")\n",
    "\n",
    "df.head(5)"
   ],
   "id": "a859699e2083c110"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Draw Candleds",
   "id": "2462e1fc2f1ed3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — Stage 2: Plot candles (line: high↔low, rectangle: open↔close)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_candles(\n",
    "    df: pd.DataFrame,\n",
    "    title: str = \"Candlestick\",\n",
    "    n_last: int | None = 300,\n",
    "    body_width: float = 0.6,     # fraction of bar spacing (0..1)\n",
    "    wick_linewidth: float = 1.2  # wick width in points\n",
    "):\n",
    "    \"\"\"Plot OHLC candles: a vertical line (low-high) and a rectangle (open-close).\"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    required = {\"open\",\"high\",\"low\",\"close\"}\n",
    "    if not required.issubset(g.columns):\n",
    "        raise ValueError(f\"DataFrame must contain {sorted(required)}\")\n",
    "\n",
    "    if n_last is not None and n_last > 0:\n",
    "        g = g.iloc[:n_last].copy()\n",
    "\n",
    "    # Convert index to matplotlib date numbers\n",
    "    x = mdates.date2num(pd.to_datetime(g.index).to_pydatetime())\n",
    "\n",
    "    # Estimate bar spacing to size bodies\n",
    "    dx = float(np.median(np.diff(x))) if len(x) > 1 else 1.0\n",
    "    bw = np.clip(body_width, 0.0, 1.0) * dx\n",
    "\n",
    "    o = g[\"open\"].to_numpy(float)\n",
    "    h = g[\"high\"].to_numpy(float)\n",
    "    l = g[\"low\"].to_numpy(float)\n",
    "    c = g[\"close\"].to_numpy(float)\n",
    "\n",
    "    up = c >= o\n",
    "    dn = ~up\n",
    "    up_color, dn_color = \"#2ca02c\", \"#d62728\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Wicks (match colors with bodies)\n",
    "    ax.vlines(x[up], l[up], h[up], linewidth=wick_linewidth, color=up_color, alpha=0.9, zorder=1)\n",
    "    ax.vlines(x[dn], l[dn], h[dn], linewidth=wick_linewidth, color=dn_color, alpha=0.9, zorder=1)\n",
    "\n",
    "    # Bodies: bottom=min(open, close), height=abs(close-open)\n",
    "    body_bottom = np.minimum(o, c)\n",
    "    body_height = np.abs(c - o)\n",
    "    ax.bar(x[up], body_height[up], bottom=body_bottom[up], width=bw, align=\"center\",\n",
    "           edgecolor=up_color, facecolor=up_color, alpha=0.75, zorder=2)\n",
    "    ax.bar(x[dn], body_height[dn], bottom=body_bottom[dn], width=bw, align=\"center\",\n",
    "           edgecolor=dn_color, facecolor=dn_color, alpha=0.75, zorder=2)\n",
    "\n",
    "    # Axis cosmetics\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    ax.xaxis_date()\n",
    "    loc = mdates.AutoDateLocator()\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(loc))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Quick preview\n",
    "plot_candles(df, title=\"Sample Candles (last 300)\", n_last=200)\n"
   ],
   "id": "7e5a224c2553f27d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Features",
   "id": "a829bab68ac2e715"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: volprof_poc_dist_100 (robust)\n",
    "FEATURE_CODE = \"volprof_poc_dist_100\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Volume Profile POC distance (100)\n",
    "    Description:\n",
    "      Relative distance from the current close to the Point of Control (POC)\n",
    "      over a 100-bar window; POC via weighted histogram mode (weights=volume).\n",
    "    Formula / method (brief):\n",
    "      For each window (size=100):\n",
    "        - Weighted histogram of close (bins=50 over [min,max]).\n",
    "        - POC := center of the max-weight bin.\n",
    "        - dist := (close_t - POC) / close_t\n",
    "    Input:\n",
    "      df with columns open, high, low, close, volume (case-insensitive).\n",
    "    Output:\n",
    "      pd.Series (float), same index, name == FEATURE_CODE; initial NaNs allowed.\n",
    "    Constraints:\n",
    "      - No look-ahead. Uses only current/past data.\n",
    "      - Numpy/Pandas only (loop over windows; reliable across pandas versions).\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    if not {\"close\",\"volume\"}.issubset(g.columns):\n",
    "        raise ValueError(\"DataFrame must contain 'close' and 'volume'.\")\n",
    "\n",
    "    c = g[\"close\"].to_numpy(float)\n",
    "    v = g[\"volume\"].to_numpy(float)\n",
    "    n = len(g); W = 100; BINS = 50\n",
    "\n",
    "    level = np.full(n, np.nan, float)\n",
    "\n",
    "    for i in range(W-1, n):\n",
    "        cs = c[i-W+1:i+1]\n",
    "        vs = v[i-W+1:i+1]\n",
    "        m = np.isfinite(cs) & np.isfinite(vs)\n",
    "        if m.sum() < 3:\n",
    "            continue\n",
    "        cs = cs[m]; vs = vs[m]\n",
    "        pmin, pmax = cs.min(), cs.max()\n",
    "        if not np.isfinite(pmin) or not np.isfinite(pmax) or pmax <= pmin:\n",
    "            continue\n",
    "        hist, edges = np.histogram(cs, bins=BINS, range=(pmin, pmax), weights=vs)\n",
    "        if hist.size == 0 or np.all(hist <= 0):\n",
    "            continue\n",
    "        j = int(np.argmax(hist))\n",
    "        level[i] = 0.5 * (edges[j] + edges[j+1])\n",
    "\n",
    "    s = (c - level) / c\n",
    "    s = pd.Series(s, index=g.index, dtype=float, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "c47dafcb30a12aad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: volprof_val_dist_100 (robust)\n",
    "FEATURE_CODE = \"volprof_val_dist_100\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Volume Profile VAL distance (100)\n",
    "    Description:\n",
    "      Relative distance from close to Value Area Low (VAL) ≈ weighted 15% quantile\n",
    "      of close over a 100-bar window (weights=volume).\n",
    "    Formula / method (brief):\n",
    "      VAL := weighted_quantile(close, weights=volume, q=0.15)\n",
    "      dist := (close_t - VAL) / close_t\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    if not {\"close\",\"volume\"}.issubset(g.columns):\n",
    "        raise ValueError(\"DataFrame must contain 'close' and 'volume'.\")\n",
    "\n",
    "    def _wq(px: np.ndarray, w: np.ndarray, q: float) -> float:\n",
    "        m = np.isfinite(px) & np.isfinite(w) & (w >= 0)\n",
    "        px = px[m]; w = w[m]\n",
    "        if px.size < 3 or w.sum() <= 0:\n",
    "            return np.nan\n",
    "        order = np.argsort(px)\n",
    "        px = px[order]; w = w[order]\n",
    "        csum = np.cumsum(w)\n",
    "        thr = q * csum[-1]\n",
    "        i = int(np.searchsorted(csum, thr, side=\"left\"))\n",
    "        i = min(max(i, 0), len(px)-1)\n",
    "        return float(px[i])\n",
    "\n",
    "    c = g[\"close\"].to_numpy(float)\n",
    "    v = g[\"volume\"].to_numpy(float)\n",
    "    n = len(g); W = 100\n",
    "\n",
    "    level = np.full(n, np.nan, float)\n",
    "    for i in range(W-1, n):\n",
    "        cs = c[i-W+1:i+1]\n",
    "        vs = v[i-W+1:i+1]\n",
    "        level[i] = _wq(cs, vs, 0.15)\n",
    "\n",
    "    s = (c - level) / c\n",
    "    s = pd.Series(s, index=g.index, dtype=float, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "d471ef8674ef7260"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: volprof_vah_dist_100 (robust)\n",
    "FEATURE_CODE = \"volprof_vah_dist_100\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Volume Profile VAH distance (100)\n",
    "    Description:\n",
    "      Relative distance from close to Value Area High (VAH) ≈ weighted 85% quantile\n",
    "      of close over a 100-bar window (weights=volume).\n",
    "    Formula / method (brief):\n",
    "      VAH := weighted_quantile(close, weights=volume, q=0.85)\n",
    "      dist := (close_t - VAH) / close_t\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    if not {\"close\",\"volume\"}.issubset(g.columns):\n",
    "        raise ValueError(\"DataFrame must contain 'close' and 'volume'.\")\n",
    "\n",
    "    def _wq(px: np.ndarray, w: np.ndarray, q: float) -> float:\n",
    "        m = np.isfinite(px) & np.isfinite(w) & (w >= 0)\n",
    "        px = px[m]; w = w[m]\n",
    "        if px.size < 3 or w.sum() <= 0:\n",
    "            return np.nan\n",
    "        order = np.argsort(px)\n",
    "        px = px[order]; w = w[order]\n",
    "        csum = np.cumsum(w)\n",
    "        thr = q * csum[-1]\n",
    "        i = int(np.searchsorted(csum, thr, side=\"left\"))\n",
    "        i = min(max(i, 0), len(px)-1)\n",
    "        return float(px[i])\n",
    "\n",
    "    c = g[\"close\"].to_numpy(float)\n",
    "    v = g[\"volume\"].to_numpy(float)\n",
    "    n = len(g); W = 100\n",
    "\n",
    "    level = np.full(n, np.nan, float)\n",
    "    for i in range(W-1, n):\n",
    "        cs = c[i-W+1:i+1]\n",
    "        vs = v[i-W+1:i+1]\n",
    "        level[i] = _wq(cs, vs, 0.85)\n",
    "\n",
    "    s = (c - level) / c\n",
    "    s = pd.Series(s, index=g.index, dtype=float, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "abdfb999c1190992"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: range_high_dist_50\n",
    "FEATURE_CODE = \"range_high_dist_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rolling Range High Distance (50)\n",
    "    Description:\n",
    "      Relative distance from the current close to the rolling 50-bar highest high.\n",
    "      Positive values mean close is above the range-high (rare), negative values\n",
    "      mean close is below the range-high (typical).\n",
    "    Formula / method (brief):\n",
    "      RH_t = max(high_{t-49..t})\n",
    "      dist_t = (close_t - RH_t) / close_t\n",
    "    Input:\n",
    "      df: DataFrame with DatetimeIndex (ascending), columns:\n",
    "           open, high, low, close, volume (case-insensitive)\n",
    "    Output:\n",
    "      pd.Series (float), same index as df.index, length == len(df),\n",
    "      name == FEATURE_CODE. Initial NaNs from rolling windows are OK.\n",
    "    Constraints:\n",
    "      - No look-ahead (uses only current and past data).\n",
    "      - Vectorized (rolling max).\n",
    "      - Uses only numpy and pandas.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]  # normalize\n",
    "\n",
    "    # Rolling 50-bar highest high (includes current bar)\n",
    "    rh = g[\"high\"].rolling(50, min_periods=50).max().astype(float)\n",
    "\n",
    "    # Relative distance from range-high\n",
    "    s = (g[\"close\"].astype(float) - rh) / g[\"close\"].astype(float)\n",
    "    s = s.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s"
   ],
   "id": "ff327914ced44c95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: range_low_dist_50\n",
    "FEATURE_CODE = \"range_low_dist_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rolling Range Low Distance (50)\n",
    "    Description:\n",
    "      Relative distance from the current close to the rolling 50-bar lowest low.\n",
    "      Positive values mean close is above the range-low (typical), negative values\n",
    "      mean close is below the range-low (rare).\n",
    "    Formula / method (brief):\n",
    "      RL_t = min(low_{t-49..t})\n",
    "      dist_t = (close_t - RL_t) / close_t\n",
    "    Input:\n",
    "      df: DataFrame with DatetimeIndex (ascending), columns:\n",
    "           open, high, low, close, volume (case-insensitive)\n",
    "    Output:\n",
    "      pd.Series (float), same index as df.index, length == len(df),\n",
    "      name == FEATURE_CODE. Initial NaNs from rolling windows are OK.\n",
    "    Constraints:\n",
    "      - No look-ahead (uses only current and past data).\n",
    "      - Vectorized (rolling min).\n",
    "      - Uses only numpy and pandas.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]  # normalize\n",
    "\n",
    "    # Rolling 50-bar lowest low (includes current bar)\n",
    "    rl = g[\"low\"].rolling(50, min_periods=50).min().astype(float)\n",
    "\n",
    "    # Relative distance from range-low\n",
    "    s = (g[\"close\"].astype(float) - rl) / g[\"close\"].astype(float)\n",
    "    s = s.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s"
   ],
   "id": "3017f4044ac46774"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: range_breakout_flag_50\n",
    "FEATURE_CODE = \"range_breakout_flag_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rolling Range Breakout Flag (50)\n",
    "    Description:\n",
    "      Discrete flag indicating breakout vs. the previous 50 bars (excluding current):\n",
    "        +1 if close_t > max(high_{t-50..t-1})  (up-breakout)\n",
    "        -1 if close_t < min(low_{t-50..t-1})   (down-breakout)\n",
    "         0 otherwise (inside the prior 50-bar range)\n",
    "    Formula / method (brief):\n",
    "      prev_high_t = max(high_{t-50..t-1}) = rolling_max(high, 50) on shifted series\n",
    "      prev_low_t  = min(low_{t-50..t-1})  = rolling_min(low, 50) on shifted series\n",
    "      flag_t = 1 if close_t > prev_high_t; -1 if close_t < prev_low_t; else 0\n",
    "    Input:\n",
    "      df: DataFrame with DatetimeIndex (ascending), columns:\n",
    "           open, high, low, close, volume (case-insensitive)\n",
    "    Output:\n",
    "      pd.Series (int), same index as df.index, length == len(df),\n",
    "      name == FEATURE_CODE. Initial NaNs from rolling windows are OK (will map to 0).\n",
    "    Constraints:\n",
    "      - No look-ahead (uses only current and past data; window excludes current via shift).\n",
    "      - Vectorized (rolling + numpy where).\n",
    "      - Uses only numpy and pandas.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]  # normalize\n",
    "\n",
    "    # Prior window (exclude current) via shift(1)\n",
    "    prev_high = g[\"high\"].shift(1).rolling(50, min_periods=50).max().astype(float)\n",
    "    prev_low  = g[\"low\"].shift(1).rolling(50, min_periods=50).min().astype(float)\n",
    "\n",
    "    c = g[\"close\"].astype(float)\n",
    "\n",
    "    up_break   = c > prev_high\n",
    "    down_break = c < prev_low\n",
    "\n",
    "    # Map to {-1, 0, +1}; NaNs in prev_* yield False in comparisons -> 0\n",
    "    flag = np.where(up_break, 1, np.where(down_break, -1, 0)).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s"
   ],
   "id": "a19938c72a04e6b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: channel_reg_upper_dist_50\n",
    "FEATURE_CODE = \"channel_reg_upper_dist_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rolling Regression Channel — Upper Distance (50)\n",
    "    Description:\n",
    "      Relative distance from the current close to the UPPER regression channel line\n",
    "      built on a 50-bar rolling linear regression of close vs. time. The channel\n",
    "      uses the regression line ± 1×(residual_std). Here residual_std is approximated\n",
    "      by sqrt( var_y * (1 - r^2) ), where r is the rolling correlation between time and close.\n",
    "      (You can change the multiplier if you want wider/narrower channels.)\n",
    "    Formula / method (brief):\n",
    "      For each window W=50:\n",
    "        - t = 0..N-1 (global index as float); y = close\n",
    "        - slope = cov(t,y)/var(t)\n",
    "          with cov, var computed via rolling means (no apply/loops).\n",
    "        - intercept = mean(y) - slope*mean(t)\n",
    "        - reg_line_t = slope * t + intercept\n",
    "        - resid_std ≈ sqrt( var_y * (1 - r^2) ), r = cov / sqrt(var_t*var_y)\n",
    "        - upper = reg_line_t + 1 * resid_std\n",
    "        - dist = (close - upper) / close\n",
    "    Input:\n",
    "      df: DataFrame with DatetimeIndex (ascending), columns:\n",
    "           open, high, low, close, volume (case-insensitive)\n",
    "    Output:\n",
    "      pd.Series (float), same index as df.index, name == FEATURE_CODE.\n",
    "      Initial NaNs from rolling windows are OK.\n",
    "    Constraints:\n",
    "      - No look-ahead.\n",
    "      - Vectorized with rolling means.\n",
    "      - Numpy & pandas only.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    y = g[\"close\"].astype(float)\n",
    "    n = len(g)\n",
    "    W = 50\n",
    "\n",
    "    # time index as float (global positions 0..n-1)\n",
    "    t = pd.Series(np.arange(n, dtype=float), index=g.index)\n",
    "\n",
    "    # rolling means\n",
    "    t_mean = t.rolling(W, min_periods=W).mean()\n",
    "    y_mean = y.rolling(W, min_periods=W).mean()\n",
    "    ty_mean = (t * y).rolling(W, min_periods=W).mean()\n",
    "    t2_mean = (t * t).rolling(W, min_periods=W).mean()\n",
    "    y2_mean = (y * y).rolling(W, min_periods=W).mean()\n",
    "\n",
    "    cov_ty = ty_mean - t_mean * y_mean\n",
    "    var_t  = t2_mean - t_mean * t_mean\n",
    "    var_y  = y2_mean - y_mean * y_mean\n",
    "\n",
    "    slope = cov_ty / var_t.replace(0.0, np.nan)\n",
    "    intercept = y_mean - slope * t_mean\n",
    "    reg_line = slope * t + intercept\n",
    "\n",
    "    # correlation r and residual std ≈ sqrt(var_y * (1 - r^2))\n",
    "    r = cov_ty / (np.sqrt(var_t) * np.sqrt(var_y))\n",
    "    resid_std = np.sqrt(np.clip(var_y * (1.0 - r * r), a_min=0.0, a_max=None))\n",
    "\n",
    "    # channel upper with multiplier m=1.0 (change if desired)\n",
    "    m = 1.0\n",
    "    upper = reg_line + m * resid_std\n",
    "\n",
    "    s = (y - upper) / y\n",
    "    s = s.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s"
   ],
   "id": "2b8eb91beffe2f30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: channel_reg_lower_dist_50\n",
    "FEATURE_CODE = \"channel_reg_lower_dist_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rolling Regression Channel — Lower Distance (50)\n",
    "    Description:\n",
    "      Relative distance from the current close to the LOWER regression channel line\n",
    "      built on a 50-bar rolling linear regression of close vs. time. The channel\n",
    "      uses the regression line ± 1×(residual_std), where residual_std ≈ sqrt(var_y*(1 - r^2)).\n",
    "    Formula / method (brief):\n",
    "      Same as the upper version, but:\n",
    "        lower = reg_line_t - 1 * resid_std\n",
    "        dist = (close - lower) / close\n",
    "    Input/Output/Constraints:\n",
    "      Same as channel_reg_upper_dist_50.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    y = g[\"close\"].astype(float)\n",
    "    n = len(g)\n",
    "    W = 50\n",
    "\n",
    "    t = pd.Series(np.arange(n, dtype=float), index=g.index)\n",
    "\n",
    "    t_mean = t.rolling(W, min_periods=W).mean()\n",
    "    y_mean = y.rolling(W, min_periods=W).mean()\n",
    "    ty_mean = (t * y).rolling(W, min_periods=W).mean()\n",
    "    t2_mean = (t * t).rolling(W, min_periods=W).mean()\n",
    "    y2_mean = (y * y).rolling(W, min_periods=W).mean()\n",
    "\n",
    "    cov_ty = ty_mean - t_mean * y_mean\n",
    "    var_t  = t2_mean - t_mean * t_mean\n",
    "    var_y  = y2_mean - y_mean * y_mean\n",
    "\n",
    "    slope = cov_ty / var_t.replace(0.0, np.nan)\n",
    "    intercept = y_mean - slope * t_mean\n",
    "    reg_line = slope * t + intercept\n",
    "\n",
    "    r = cov_ty / (np.sqrt(var_t) * np.sqrt(var_y))\n",
    "    resid_std = np.sqrt(np.clip(var_y * (1.0 - r * r), a_min=0.0, a_max=None))\n",
    "\n",
    "    m = 1.0\n",
    "    lower = reg_line - m * resid_std\n",
    "\n",
    "    s = (y - lower) / y\n",
    "    s = s.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "10e095a3a0809293"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: trendline_touch_flag_100\n",
    "FEATURE_CODE = \"trendline_touch_flag_100\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Trendline Touch Flag (100)\n",
    "    Description:\n",
    "      Binary flag indicating whether the current close is \"touching\" the rolling\n",
    "      regression trendline (close vs. time) over a 100-bar window, within a tolerance\n",
    "      proportional to the window's residual standard deviation.\n",
    "    Formula / method (brief):\n",
    "      For each window W=100:\n",
    "        - Compute slope/intercept of OLS(y~t); reg_line_t = slope*t + intercept\n",
    "        - resid = close - reg_line_t\n",
    "        - resid_std ≈ sqrt(var_y * (1 - r^2))\n",
    "        - flag = 1 if |resid| <= tol_mult * resid_std  else 0\n",
    "      Here tol_mult = 0.25 (change if you prefer).\n",
    "    Input:\n",
    "      df: DataFrame with DatetimeIndex (ascending), columns:\n",
    "           open, high, low, close, volume (case-insensitive)\n",
    "    Output:\n",
    "      pd.Series (int), values in {0,1}, same index as df.index, name == FEATURE_CODE.\n",
    "    Constraints:\n",
    "      - No look-ahead; vectorized with rolling means.\n",
    "      - Numpy & pandas only.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    y = g[\"close\"].astype(float)\n",
    "    n = len(g)\n",
    "    W = 100\n",
    "    tol_mult = 0.25\n",
    "\n",
    "    t = pd.Series(np.arange(n, dtype=float), index=g.index)\n",
    "\n",
    "    t_mean = t.rolling(W, min_periods=W).mean()\n",
    "    y_mean = y.rolling(W, min_periods=W).mean()\n",
    "    ty_mean = (t * y).rolling(W, min_periods=W).mean()\n",
    "    t2_mean = (t * t).rolling(W, min_periods=W).mean()\n",
    "    y2_mean = (y * y).rolling(W, min_periods=W).mean()\n",
    "\n",
    "    cov_ty = ty_mean - t_mean * y_mean\n",
    "    var_t  = t2_mean - t_mean * t_mean\n",
    "    var_y  = y2_mean - y_mean * y_mean\n",
    "\n",
    "    slope = cov_ty / var_t.replace(0.0, np.nan)\n",
    "    intercept = y_mean - slope * t_mean\n",
    "    reg_line = slope * t + intercept\n",
    "\n",
    "    # residual & residual std\n",
    "    resid = y - reg_line\n",
    "    r = cov_ty / (np.sqrt(var_t) * np.sqrt(var_y))\n",
    "    resid_std = np.sqrt(np.clip(var_y * (1.0 - r * r), a_min=0.0, a_max=None))\n",
    "\n",
    "    flag = (resid.abs() <= (tol_mult * resid_std)).astype(int)\n",
    "    flag.name = FEATURE_CODE\n",
    "    return flag\n"
   ],
   "id": "8787f04059ef559c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: trendline_slope_100\n",
    "FEATURE_CODE = \"trendline_slope_100\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Trendline Slope (100)\n",
    "    Description:\n",
    "      Rolling OLS slope of close vs. time over a 100-bar window. This is the same\n",
    "      idea as reg_lin_slope_W, but with W=100; it measures the per-bar trend\n",
    "      (positive uptrend, negative downtrend).\n",
    "    Formula / method (brief):\n",
    "      slope_t = cov(t,y) / var(t), where cov/var computed via rolling means.\n",
    "    Input:\n",
    "      df: DataFrame with DatetimeIndex (ascending), columns:\n",
    "           open, high, low, close, volume (case-insensitive)\n",
    "    Output:\n",
    "      pd.Series (float), same index as df.index, name == FEATURE_CODE.\n",
    "    Constraints:\n",
    "      - No look-ahead; vectorized with rolling means.\n",
    "      - Numpy & pandas only.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    y = g[\"close\"].astype(float)\n",
    "    n = len(g)\n",
    "    W = 100\n",
    "\n",
    "    t = pd.Series(np.arange(n, dtype=float), index=g.index)\n",
    "\n",
    "    t_mean = t.rolling(W, min_periods=W).mean()\n",
    "    y_mean = y.rolling(W, min_periods=W).mean()\n",
    "    cov = (t * y).rolling(W, min_periods=W).mean() - t_mean * y_mean\n",
    "    var = (t * t).rolling(W, min_periods=W).mean() - t_mean * t_mean\n",
    "\n",
    "    slope = cov / var.replace(0.0, np.nan)\n",
    "    slope = slope.astype(float)\n",
    "    slope.name = FEATURE_CODE\n",
    "    return slope\n"
   ],
   "id": "762cdeff79bed6a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: pivot_classic_pp_dist_1d\n",
    "FEATURE_CODE = \"pivot_classic_pp_dist_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Classic Pivot Point distance (previous day)\n",
    "    Description:\n",
    "      Relative distance from the current close to the prior day's Classic Pivot Point (PP).\n",
    "      PP_prev_day = (H_prev + L_prev + C_prev) / 3, computed from the previous trading day.\n",
    "    Formula / method (brief):\n",
    "      - Aggregate intraday into daily H/L/C via groupby(normalized date).\n",
    "      - Shift by 1 day to avoid look-ahead.\n",
    "      - PP = (H_prev + L_prev + C_prev)/3\n",
    "      - dist = (close_t - PP_for_today)/close_t\n",
    "    Input:\n",
    "      df: DataFrame with DatetimeIndex (ascending), columns:\n",
    "           open, high, low, close, volume (case-insensitive)\n",
    "    Output:\n",
    "      pd.Series (float), same index as df.index, name == FEATURE_CODE.\n",
    "      First day(s) will be NaN (no prior day).\n",
    "    Constraints:\n",
    "      - No look-ahead (uses prior day levels only).\n",
    "      - Vectorized (groupby + map).\n",
    "      - Uses numpy and pandas only.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]  # normalize\n",
    "    days = g.index.normalize()\n",
    "\n",
    "    # Daily OHLC (based on intraday)\n",
    "    daily = g.assign(__day=days).groupby(\"__day\").agg(\n",
    "        high=(\"high\", \"max\"),\n",
    "        low=(\"low\", \"min\"),\n",
    "        close=(\"close\", \"last\"),\n",
    "    )\n",
    "\n",
    "    # Previous-day pivots\n",
    "    daily_prev = daily.shift(1)\n",
    "    pp_daily = (daily_prev[\"high\"] + daily_prev[\"low\"] + daily_prev[\"close\"]) / 3.0\n",
    "\n",
    "    # Map each intraday bar's day -> that day's PP (from previous day)\n",
    "    pp_intraday = pd.Series(pd.Index(days).map(pp_daily), index=g.index, dtype=float)\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - pp_intraday) / g[\"close\"].astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s"
   ],
   "id": "d8aafa8b6b803375"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: pivot_classic_r1_dist_1d\n",
    "FEATURE_CODE = \"pivot_classic_r1_dist_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Classic Pivot R1 distance (previous day)\n",
    "    Description:\n",
    "      Relative distance from close to prior day's Classic R1.\n",
    "      R1_prev = 2*PP_prev - L_prev, where PP_prev = (H_prev+L_prev+C_prev)/3.\n",
    "    Formula / method (brief):\n",
    "      - Daily OHLC from intraday; shift by 1 to get prior day.\n",
    "      - Compute PP_prev, then R1_prev.\n",
    "      - dist = (close_t - R1_today)/close_t\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    days = g.index.normalize()\n",
    "\n",
    "    daily = g.assign(__day=days).groupby(\"__day\").agg(\n",
    "        high=(\"high\", \"max\"),\n",
    "        low=(\"low\", \"min\"),\n",
    "        close=(\"close\", \"last\"),\n",
    "    )\n",
    "    dprev = daily.shift(1)\n",
    "    pp = (dprev[\"high\"] + dprev[\"low\"] + dprev[\"close\"]) / 3.0\n",
    "    r1_daily = 2.0 * pp - dprev[\"low\"]\n",
    "\n",
    "    r1_intraday = pd.Series(pd.Index(days).map(r1_daily), index=g.index, dtype=float)\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - r1_intraday) / g[\"close\"].astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "67598e40c3052d7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: pivot_classic_r2_dist_1d\n",
    "FEATURE_CODE = \"pivot_classic_r2_dist_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Classic Pivot R2 distance (previous day)\n",
    "    Description:\n",
    "      Relative distance from close to prior day's Classic R2.\n",
    "      R2_prev = PP_prev + (H_prev - L_prev), where PP_prev = (H_prev+L_prev+C_prev)/3.\n",
    "    Formula / method (brief):\n",
    "      - Daily OHLC from intraday; shift by 1.\n",
    "      - Compute PP_prev, then R2_prev.\n",
    "      - dist = (close_t - R2_today)/close_t\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    days = g.index.normalize()\n",
    "\n",
    "    daily = g.assign(__day=days).groupby(\"__day\").agg(\n",
    "        high=(\"high\", \"max\"),\n",
    "        low=(\"low\", \"min\"),\n",
    "        close=(\"close\", \"last\"),\n",
    "    )\n",
    "    dprev = daily.shift(1)\n",
    "    pp = (dprev[\"high\"] + dprev[\"low\"] + dprev[\"close\"]) / 3.0\n",
    "    r2_daily = pp + (dprev[\"high\"] - dprev[\"low\"])\n",
    "\n",
    "    r2_intraday = pd.Series(pd.Index(days).map(r2_daily), index=g.index, dtype=float)\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - r2_intraday) / g[\"close\"].astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "b689e52b1015ab7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: pivot_classic_s1_dist_1d\n",
    "FEATURE_CODE = \"pivot_classic_s1_dist_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Classic Pivot S1 distance (previous day)\n",
    "    Description:\n",
    "      Relative distance from close to prior day's Classic S1.\n",
    "      S1_prev = 2*PP_prev - H_prev, where PP_prev = (H_prev+L_prev+C_prev)/3.\n",
    "    Formula / method (brief):\n",
    "      - Daily OHLC from intraday; shift by 1.\n",
    "      - Compute PP_prev, then S1_prev.\n",
    "      - dist = (close_t - S1_today)/close_t\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    days = g.index.normalize()\n",
    "\n",
    "    daily = g.assign(__day=days).groupby(\"__day\").agg(\n",
    "        high=(\"high\", \"max\"),\n",
    "        low=(\"low\", \"min\"),\n",
    "        close=(\"close\", \"last\"),\n",
    "    )\n",
    "    dprev = daily.shift(1)\n",
    "    pp = (dprev[\"high\"] + dprev[\"low\"] + dprev[\"close\"]) / 3.0\n",
    "    s1_daily = 2.0 * pp - dprev[\"high\"]\n",
    "\n",
    "    s1_intraday = pd.Series(pd.Index(days).map(s1_daily), index=g.index, dtype=float)\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - s1_intraday) / g[\"close\"].astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "bc979bfc281ee8b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: pivot_classic_s2_dist_1d\n",
    "FEATURE_CODE = \"pivot_classic_s2_dist_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Classic Pivot S2 distance (previous day)\n",
    "    Description:\n",
    "      Relative distance from close to prior day's Classic S2.\n",
    "      S2_prev = PP_prev - (H_prev - L_prev), where PP_prev = (H_prev+L_prev+C_prev)/3.\n",
    "    Formula / method (brief):\n",
    "      - Daily OHLC from intraday; shift by 1.\n",
    "      - Compute PP_prev, then S2_prev.\n",
    "      - dist = (close_t - S2_today)/close_t\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    days = g.index.normalize()\n",
    "\n",
    "    daily = g.assign(__day=days).groupby(\"__day\").agg(\n",
    "        high=(\"high\", \"max\"),\n",
    "        low=(\"low\", \"min\"),\n",
    "        close=(\"close\", \"last\"),\n",
    "    )\n",
    "    dprev = daily.shift(1)\n",
    "    pp = (dprev[\"high\"] + dprev[\"low\"] + dprev[\"close\"]) / 3.0\n",
    "    s2_daily = pp - (dprev[\"high\"] - dprev[\"low\"])\n",
    "\n",
    "    s2_intraday = pd.Series(pd.Index(days).map(s2_daily), index=g.index, dtype=float)\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - s2_intraday) / g[\"close\"].astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "a43e17b5c6035188"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: mom_rsi_div_flag_14_5\n",
    "FEATURE_CODE = \"mom_rsi_div_flag_14_5\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    RSI Divergence Flag (RSI-14, lookback 5)\n",
    "    Description:\n",
    "      Flags simple bullish/bearish divergences between price and RSI:\n",
    "        +1 (bullish): price makes a lower low vs prior 5 bars while RSI does NOT make a lower low.\n",
    "        -1 (bearish): price makes a higher high vs prior 5 bars while RSI does NOT make a higher high.\n",
    "         0 otherwise.\n",
    "      (This is a lightweight, vectorized approximation of swing-based divergences.)\n",
    "    Formula / method (brief, cite if needed):\n",
    "      - RSI(14) via Wilder smoothing:\n",
    "          gain = max(diff(close), 0), loss = max(-diff(close), 0)\n",
    "          avg_gain = ewm(gain, alpha=1/14), avg_loss = ewm(loss, alpha=1/14)\n",
    "          RS = avg_gain/avg_loss; RSI = 100 - 100/(1+RS)\n",
    "      - With lookback L=5:\n",
    "          prev_high  = rolling_max(close.shift(1), L)\n",
    "          prev_low   = rolling_min(close.shift(1), L)\n",
    "          prev_rsi_hi = rolling_max(RSI.shift(1), L)\n",
    "          prev_rsi_lo = rolling_min(RSI.shift(1), L)\n",
    "        bearish_div = (close > prev_high) & (RSI <= prev_rsi_hi - eps)\n",
    "        bullish_div = (close < prev_low)  & (RSI >= prev_rsi_lo + eps)\n",
    "      - flag = +1 if bullish_div, -1 if bearish_div, else 0\n",
    "    Input:\n",
    "      df: DataFrame with DatetimeIndex (ascending), columns:\n",
    "           open, high, low, close, volume (case-insensitive)\n",
    "    Output:\n",
    "      pd.Series (int), values in {-1,0,+1}, same index as df.index, name == FEATURE_CODE.\n",
    "      Initial NaNs from rolling windows are OK (mapped to 0 by comparisons).\n",
    "    Constraints:\n",
    "      - No look-ahead (all comparisons use shifted/rolling past data).\n",
    "      - Vectorized; numpy and pandas only.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    close = g[\"close\"].astype(float)\n",
    "    delta = close.diff()\n",
    "\n",
    "    gain = delta.clip(lower=0.0)\n",
    "    loss = (-delta).clip(lower=0.0)\n",
    "\n",
    "    alpha = 1.0 / 14.0\n",
    "    avg_gain = gain.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "    avg_loss = loss.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss.replace(0.0, np.nan)\n",
    "    rsi = 100.0 - 100.0 / (1.0 + rs)\n",
    "    rsi = rsi.clip(0.0, 100.0)\n",
    "\n",
    "    L = 5\n",
    "    prev_high   = g[\"close\"].shift(1).rolling(L, min_periods=L).max()\n",
    "    prev_low    = g[\"close\"].shift(1).rolling(L, min_periods=L).min()\n",
    "    prev_rsi_hi = rsi.shift(1).rolling(L, min_periods=L).max()\n",
    "    prev_rsi_lo = rsi.shift(1).rolling(L, min_periods=L).min()\n",
    "\n",
    "    eps = 0.1  # tiny tolerance\n",
    "    bearish = (close > prev_high) & (rsi <= (prev_rsi_hi - eps))\n",
    "    bullish = (close < prev_low)  & (rsi >= (prev_rsi_lo + eps))\n",
    "\n",
    "    flag = np.where(bullish, 1, np.where(bearish, -1, 0)).astype(int)\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "c90f19b9986496be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: trend_sma_cross_flag_5_20\n",
    "FEATURE_CODE = \"trend_sma_cross_flag_5_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    SMA Crossover Flag (5 vs 20)\n",
    "    Description:\n",
    "      Discrete flag for moving-average crossovers:\n",
    "        +1 when SMA(5) crosses ABOVE SMA(20) at current bar,\n",
    "        -1 when SMA(5) crosses BELOW SMA(20) at current bar,\n",
    "         0 otherwise.\n",
    "    Formula / method (brief):\n",
    "      s5  = SMA(close, 5), s20 = SMA(close, 20)\n",
    "      d   = s5 - s20\n",
    "      cross_up   if d>0 and d.shift(1)<=0\n",
    "      cross_down if d<0 and d.shift(1)>=0\n",
    "      flag = +1/-1/0\n",
    "    Input / Output / Constraints:\n",
    "      As per base structure; vectorized; no look-ahead.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    s5  = g[\"close\"].rolling(5,  min_periods=5).mean()\n",
    "    s20 = g[\"close\"].rolling(20, min_periods=20).mean()\n",
    "    d = s5 - s20\n",
    "\n",
    "    cross_up   = (d > 0) & (d.shift(1) <= 0)\n",
    "    cross_down = (d < 0) & (d.shift(1) >= 0)\n",
    "\n",
    "    flag = np.where(cross_up, 1, np.where(cross_down, -1, 0)).astype(int)\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "90262a948c939102"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: ichimoku_tenkan_dist_9\n",
    "FEATURE_CODE = \"ichimoku_tenkan_dist_9\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Ichimoku Tenkan Distance (9)\n",
    "    Description:\n",
    "      Relative distance from close to Tenkan-sen over 9 bars.\n",
    "      Tenkan(9) = (rolling_high_9 + rolling_low_9) / 2.\n",
    "    Formula / method (brief):\n",
    "      hi9 = rolling max(high, 9); lo9 = rolling min(low, 9)\n",
    "      tenkan = (hi9 + lo9)/2\n",
    "      dist = (close - tenkan)/close\n",
    "    Input/Output/Constraints:\n",
    "      Standard; no look-ahead; vectorized.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    hi9 = g[\"high\"].rolling(9, min_periods=9).max()\n",
    "    lo9 = g[\"low\"].rolling(9, min_periods=9).min()\n",
    "    tenkan = (hi9 + lo9) / 2.0\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - tenkan) / g[\"close\"].astype(float)\n",
    "    s = s.astype(float); s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "d0c064fa17733298"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: ichimoku_kijun_dist_26\n",
    "FEATURE_CODE = \"ichimoku_kijun_dist_26\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Ichimoku Kijun Distance (26)\n",
    "    Description:\n",
    "      Relative distance from close to Kijun-sen over 26 bars.\n",
    "      Kijun(26) = (rolling_high_26 + rolling_low_26) / 2.\n",
    "    Formula:\n",
    "      hi26 = rolling max(high,26); lo26 = rolling min(low,26)\n",
    "      kijun = (hi26 + lo26)/2\n",
    "      dist = (close - kijun)/close\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    hi26 = g[\"high\"].rolling(26, min_periods=26).max()\n",
    "    lo26 = g[\"low\"].rolling(26, min_periods=26).min()\n",
    "    kijun = (hi26 + lo26) / 2.0\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - kijun) / g[\"close\"].astype(float)\n",
    "    s = s.astype(float); s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "8eece398a6547d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: ichimoku_span_a_dist_52\n",
    "FEATURE_CODE = \"ichimoku_span_a_dist_52\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Ichimoku Senkou Span A Distance (lag-aligned)\n",
    "    Description:\n",
    "      Relative distance from close to Senkou Span A, aligned to current bar without look-ahead.\n",
    "      Standard Span A is (Tenkan+Kijun)/2 shifted 26 bars forward. To avoid look-ahead,\n",
    "      we use the unshifted value (equivalently, the standard Span A shifted BACK by 26),\n",
    "      which depends only on past data.\n",
    "    Formula / method (brief):\n",
    "      tenkan = (max(high,9) + min(low,9))/2\n",
    "      kijun  = (max(high,26)+ min(low,26))/2\n",
    "      spanA_unshifted = (tenkan + kijun)/2\n",
    "      dist = (close - spanA_unshifted)/close\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    hi9  = g[\"high\"].rolling(9,  min_periods=9 ).max()\n",
    "    lo9  = g[\"low\"] .rolling(9,  min_periods=9 ).min()\n",
    "    tenk = (hi9 + lo9) / 2.0\n",
    "\n",
    "    hi26 = g[\"high\"].rolling(26, min_periods=26).max()\n",
    "    lo26 = g[\"low\"] .rolling(26, min_periods=26).min()\n",
    "    kij  = (hi26 + lo26) / 2.0\n",
    "\n",
    "    span_a = (tenk + kij) / 2.0  # lag-aligned (no forward shift)\n",
    "    s = (g[\"close\"].astype(float) - span_a) / g[\"close\"].astype(float)\n",
    "    s = s.astype(float); s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "6819e05c72583480"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: ichimoku_span_b_dist_52\n",
    "FEATURE_CODE = \"ichimoku_span_b_dist_52\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Ichimoku Senkou Span B Distance (lag-aligned, 52)\n",
    "    Description:\n",
    "      Relative distance from close to Senkou Span B over 52 bars, aligned to current bar\n",
    "      without look-ahead. Standard Span B = (max(high,52)+min(low,52))/2 shifted 26 forward;\n",
    "      here we use the unshifted value (equivalently, standard Span B shifted BACK 26),\n",
    "      which uses only past data at each row.\n",
    "    Formula:\n",
    "      hi52 = rolling max(high,52); lo52 = rolling min(low,52)\n",
    "      spanB_unshifted = (hi52 + lo52)/2\n",
    "      dist = (close - spanB_unshifted)/close\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    hi52 = g[\"high\"].rolling(52, min_periods=52).max()\n",
    "    lo52 = g[\"low\"] .rolling(52, min_periods=52).min()\n",
    "    span_b = (hi52 + lo52) / 2.0\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - span_b) / g[\"close\"].astype(float)\n",
    "    s = s.astype(float); s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "73a7c527e234762b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: ichimoku_cloud_thickness_52\n",
    "FEATURE_CODE = \"ichimoku_cloud_thickness_52\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Ichimoku Cloud Thickness (lag-aligned, 52)\n",
    "    Description:\n",
    "      Normalized thickness of the Ichimoku cloud at the current bar (no look-ahead),\n",
    "      defined as |SpanA - SpanB| / close. Both spans are the lag-aligned versions:\n",
    "        SpanA = (Tenkan + Kijun)/2  (unshifted)\n",
    "        SpanB = (max(high,52) + min(low,52))/2  (unshifted)\n",
    "    Formula:\n",
    "      tenkan(9), kijun(26), spanA=(tenkan+kijun)/2; spanB=(hi52+lo52)/2\n",
    "      thickness = abs(spanA - spanB)/close\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    hi9  = g[\"high\"].rolling(9,  min_periods=9 ).max()\n",
    "    lo9  = g[\"low\"] .rolling(9,  min_periods=9 ).min()\n",
    "    tenk = (hi9 + lo9) / 2.0\n",
    "\n",
    "    hi26 = g[\"high\"].rolling(26, min_periods=26).max()\n",
    "    lo26 = g[\"low\"] .rolling(26, min_periods=26).min()\n",
    "    kij  = (hi26 + lo26) / 2.0\n",
    "\n",
    "    span_a = (tenk + kij) / 2.0\n",
    "    hi52 = g[\"high\"].rolling(52, min_periods=52).max()\n",
    "    lo52 = g[\"low\"] .rolling(52, min_periods=52).min()\n",
    "    span_b = (hi52 + lo52) / 2.0\n",
    "\n",
    "    thickness = (span_a - span_b).abs() / g[\"close\"].astype(float)\n",
    "    thickness = thickness.astype(float)\n",
    "    thickness.name = FEATURE_CODE\n",
    "    return thickness\n"
   ],
   "id": "677fa1140f9b22c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: band_gauss_upper_dist_20_2\n",
    "FEATURE_CODE = \"band_gauss_upper_dist_20_2\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Gaussian/Bollinger Upper Band Distance (20, 2σ)\n",
    "    Description:\n",
    "      Relative distance from close to the upper Gaussian band:\n",
    "        upper = SMA(close,20) + 2 * std(close,20, ddof=0)\n",
    "      (This is the common Bollinger upper band with 20 periods, 2 standard deviations.)\n",
    "    Formula / method (brief):\n",
    "      ma20 = rolling mean(close,20); sd20 = rolling std(close,20) with ddof=0\n",
    "      upper = ma20 + 2*sd20\n",
    "      dist = (close - upper)/close\n",
    "    Input/Output/Constraints:\n",
    "      Standard; vectorized; no look-ahead.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    ma20 = g[\"close\"].rolling(20, min_periods=20).mean()\n",
    "    sd20 = g[\"close\"].rolling(20, min_periods=20).std(ddof=0)  # population std\n",
    "    upper = ma20 + 2.0 * sd20\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - upper) / g[\"close\"].astype(float)\n",
    "    s = s.astype(float); s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "64fb89fe3dbc22bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: regime_range_flag_adx_14\n",
    "FEATURE_CODE = \"regime_range_flag_adx_14\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Regime: Range Flag via ADX (14)\n",
    "    Description:\n",
    "      Flags 1 when ADX(14) < 20 (weak trend), suggesting a ranging/sideways regime. Else 0.\n",
    "    Method:\n",
    "      Same ADX pipeline as above; only final condition changes to (ADX < 20).\n",
    "    \"\"\"\n",
    "    g = df.copy(); g.columns = [str(c).lower() for c in g.columns]\n",
    "    h, l, c = g[\"high\"].astype(float), g[\"low\"].astype(float), g[\"close\"].astype(float)\n",
    "\n",
    "    up_move   = h.diff()\n",
    "    down_move = -l.diff()\n",
    "\n",
    "    plus_dm  = np.where((up_move > down_move) & (up_move > 0),  up_move,  0.0)\n",
    "    minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
    "    plus_dm  = pd.Series(plus_dm, index=g.index)\n",
    "    minus_dm = pd.Series(minus_dm, index=g.index)\n",
    "\n",
    "    tr = pd.concat([(h - l), (h - c.shift(1)).abs(), (l - c.shift(1)).abs()], axis=1).max(axis=1)\n",
    "\n",
    "    alpha = 1/14\n",
    "    tr_sm     = tr.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "    plus_sm   = plus_dm.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "    minus_sm  = minus_dm.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "\n",
    "    plus_di  = 100.0 * (plus_sm  / tr_sm.replace(0.0, np.nan))\n",
    "    minus_di = 100.0 * (minus_sm / tr_sm.replace(0.0, np.nan))\n",
    "\n",
    "    dx = 100.0 * (plus_di - minus_di).abs() / (plus_di + minus_di).replace(0.0, np.nan)\n",
    "    adx = dx.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "\n",
    "    flag = (adx < 20.0).astype(int).fillna(0)\n",
    "    s = pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "e5f4031c26e76d97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: regime_trend_down_flag_adx_14\n",
    "FEATURE_CODE = \"regime_trend_down_flag_adx_14\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Regime: Downtrend Flag via ADX (14)\n",
    "    Description:\n",
    "      Flags 1 when ADX(14) >= 20 and -DI > +DI (trend strength + negative direction). Else 0.\n",
    "    Method:\n",
    "      Same ADX pipeline as the uptrend version, final condition reversed.\n",
    "    \"\"\"\n",
    "    g = df.copy(); g.columns = [str(c).lower() for c in g.columns]\n",
    "    h, l, c = g[\"high\"].astype(float), g[\"low\"].astype(float), g[\"close\"].astype(float)\n",
    "\n",
    "    up_move   = h.diff()\n",
    "    down_move = -l.diff()\n",
    "\n",
    "    plus_dm  = np.where((up_move > down_move) & (up_move > 0),  up_move,  0.0)\n",
    "    minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
    "    plus_dm  = pd.Series(plus_dm, index=g.index)\n",
    "    minus_dm = pd.Series(minus_dm, index=g.index)\n",
    "\n",
    "    tr = pd.concat([(h - l), (h - c.shift(1)).abs(), (l - c.shift(1)).abs()], axis=1).max(axis=1)\n",
    "\n",
    "    alpha = 1/14\n",
    "    tr_sm     = tr.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "    plus_sm   = plus_dm.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "    minus_sm  = minus_dm.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "\n",
    "    plus_di  = 100.0 * (plus_sm  / tr_sm.replace(0.0, np.nan))\n",
    "    minus_di = 100.0 * (minus_sm / tr_sm.replace(0.0, np.nan))\n",
    "\n",
    "    dx = 100.0 * (plus_di - minus_di).abs() / (plus_di + minus_di).replace(0.0, np.nan)\n",
    "    adx = dx.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "\n",
    "    flag = ((adx >= 20.0) & (minus_di > plus_di)).astype(int).fillna(0)\n",
    "    s = pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "860390fc21346e39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: regime_trend_up_flag_adx_14\n",
    "FEATURE_CODE = \"regime_trend_up_flag_adx_14\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Regime: Uptrend Flag via ADX (14)\n",
    "    Description:\n",
    "      Flags 1 when ADX(14) >= 20 and +DI > -DI (trend strength + positive direction). Else 0.\n",
    "    Method (Wilder approximations using EWM as proxy):\n",
    "      +DM = max(high_t - high_{t-1}, 0) if > (low_{t-1} - low_t) else 0\n",
    "      -DM = max(low_{t-1} - low_t, 0)  if > (high_t - high_{t-1}) else 0\n",
    "      TR  = max(high-low, |high-close_{t-1}|, |low-close_{t-1}|)\n",
    "      Smooth with EWM(alpha=1/14, adjust=False, min_periods=14)\n",
    "      +DI = 100 * (+DM_sm / TR_sm); -DI = 100 * (-DM_sm / TR_sm)\n",
    "      DX  = 100 * |(+DI - -DI)| / (+DI + -DI)\n",
    "      ADX = EWM(DX, alpha=1/14, adjust=False, min_periods=14)\n",
    "      flag = 1 if (ADX>=20) & (+DI > -DI) else 0\n",
    "    \"\"\"\n",
    "    g = df.copy(); g.columns = [str(c).lower() for c in g.columns]\n",
    "    h, l, c = g[\"high\"].astype(float), g[\"low\"].astype(float), g[\"close\"].astype(float)\n",
    "\n",
    "    up_move   = h.diff()\n",
    "    down_move = -l.diff()\n",
    "\n",
    "    plus_dm  = np.where((up_move > down_move) & (up_move > 0),  up_move,  0.0)\n",
    "    minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
    "    plus_dm  = pd.Series(plus_dm, index=g.index)\n",
    "    minus_dm = pd.Series(minus_dm, index=g.index)\n",
    "\n",
    "    tr = pd.concat([(h - l), (h - c.shift(1)).abs(), (l - c.shift(1)).abs()], axis=1).max(axis=1)\n",
    "\n",
    "    alpha = 1/14\n",
    "    tr_sm     = tr.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "    plus_sm   = plus_dm.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "    minus_sm  = minus_dm.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "\n",
    "    plus_di  = 100.0 * (plus_sm  / tr_sm.replace(0.0, np.nan))\n",
    "    minus_di = 100.0 * (minus_sm / tr_sm.replace(0.0, np.nan))\n",
    "\n",
    "    dx = 100.0 * (plus_di - minus_di).abs() / (plus_di + minus_di).replace(0.0, np.nan)\n",
    "    adx = dx.ewm(alpha=alpha, adjust=False, min_periods=14).mean()\n",
    "\n",
    "    flag = ((adx >= 20.0) & (plus_di > minus_di)).astype(int).fillna(0)\n",
    "    s = pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "64652a13ef6feeb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: regime_trend_down_flag_slopeatr_50_14\n",
    "FEATURE_CODE = \"regime_trend_down_flag_slope_50_atr_14\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Regime: Downtrend Flag via Regression Slope normalized by ATR (W=50, ATR=14)\n",
    "    Description:\n",
    "      Flags 1 when rolling OLS slope(close~time,50) normalized by ATR(14) is below −k (k=0.05),\n",
    "      implying a persistent downward drift vs. volatility. Else 0.\n",
    "    Method:\n",
    "      Same slope/ATR as the uptrend version.\n",
    "      z = slope50 / atr14\n",
    "      flag = 1 if z <= -k else 0\n",
    "    \"\"\"\n",
    "    g = df.copy(); g.columns = [str(c).lower() for c in g.columns]\n",
    "    y = g[\"close\"].astype(float)\n",
    "    n = len(g); W = 50\n",
    "\n",
    "    t = pd.Series(np.arange(n, dtype=float), index=g.index)\n",
    "    t_mean = t.rolling(W, min_periods=W).mean()\n",
    "    y_mean = y.rolling(W, min_periods=W).mean()\n",
    "    cov = (t*y).rolling(W, min_periods=W).mean() - t_mean*y_mean\n",
    "    var = (t*t).rolling(W, min_periods=W).mean() - t_mean*t_mean\n",
    "    slope = cov / var.replace(0.0, np.nan)\n",
    "\n",
    "    h, l, c = g[\"high\"].astype(float), g[\"low\"].astype(float), g[\"close\"].astype(float)\n",
    "    tr = pd.concat([\n",
    "        (h - l),\n",
    "        (h - c.shift(1)).abs(),\n",
    "        (l - c.shift(1)).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "    atr14 = tr.ewm(alpha=1/14, adjust=False, min_periods=14).mean()\n",
    "\n",
    "    z = slope / atr14.replace(0.0, np.nan)\n",
    "    k = 0.05\n",
    "    flag = (z <= -k).astype(int).fillna(0)\n",
    "    s = pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "84ace2dea87bf40a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: regime_trend_up_flag_slopeatr_50_14\n",
    "FEATURE_CODE = \"regime_trend_up_flag_slope_50_atr_14\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Regime: Uptrend Flag via Regression Slope normalized by ATR (W=50, ATR=14)\n",
    "    Description:\n",
    "      Flags 1 when rolling OLS slope(close~time,50) normalized by ATR(14) is above +k (k=0.05 by default),\n",
    "      implying a persistent upward drift vs. recent volatility. Else 0.\n",
    "    Method:\n",
    "      slope50 = cov(t,y)/var(t) using rolling means (y=close, t=0..N-1)\n",
    "      atr14 = Wilder ATR(14) on high/low/close\n",
    "      z = slope50 / atr14\n",
    "      flag = 1 if z >= k else 0   (k = 0.05)\n",
    "    Notes:\n",
    "      - Units: slope is price/bar; dividing by ATR (price units) yields per-bar in ATR units.\n",
    "    \"\"\"\n",
    "    g = df.copy(); g.columns = [str(c).lower() for c in g.columns]\n",
    "    y = g[\"close\"].astype(float)\n",
    "    n = len(g); W = 50\n",
    "\n",
    "    # Rolling OLS slope\n",
    "    t = pd.Series(np.arange(n, dtype=float), index=g.index)\n",
    "    t_mean = t.rolling(W, min_periods=W).mean()\n",
    "    y_mean = y.rolling(W, min_periods=W).mean()\n",
    "    cov = (t*y).rolling(W, min_periods=W).mean() - t_mean*y_mean\n",
    "    var = (t*t).rolling(W, min_periods=W).mean() - t_mean*t_mean\n",
    "    slope = cov / var.replace(0.0, np.nan)\n",
    "\n",
    "    # ATR(14) — Wilder\n",
    "    h, l, c = g[\"high\"].astype(float), g[\"low\"].astype(float), g[\"close\"].astype(float)\n",
    "    tr = pd.concat([\n",
    "        (h - l),\n",
    "        (h - c.shift(1)).abs(),\n",
    "        (l - c.shift(1)).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "    atr14 = tr.ewm(alpha=1/14, adjust=False, min_periods=14).mean()\n",
    "\n",
    "    z = slope / atr14.replace(0.0, np.nan)\n",
    "    k = 0.05\n",
    "    flag = (z >= k).astype(int).fillna(0)\n",
    "    s = pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "b628e08402598e36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: regime_range_flag_bb_20_q20\n",
    "FEATURE_CODE = \"regime_range_flag_bb_20_q20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Regime: Range Flag via Bollinger Bandwidth (BB(20), below 20th percentile over 120 bars)\n",
    "    Description:\n",
    "      Flags 1 when the 20-bar Bollinger Bandwidth is unusually low (<= rolling 20% quantile over 120 bars),\n",
    "      which often corresponds to ranging/sideways regimes. Otherwise 0.\n",
    "    Method:\n",
    "      ma20 = SMA(close,20); sd20 = STD(close,20, ddof=0)\n",
    "      bbw20 = (upper - lower) / ma20 = (2*sd20 + 2*sd20) / ma20 = 4*sd20/ma20\n",
    "      thresh = rolling_quantile(bbw20, window=120, q=0.20) (using pandas.Series.quantile on rolling)\n",
    "      flag = 1 if bbw20 <= thresh else 0\n",
    "    Constraints:\n",
    "      - No look-ahead (threshold is from rolling past+current window).\n",
    "      - Vectorized; numpy & pandas only.\n",
    "    \"\"\"\n",
    "    g = df.copy(); g.columns = [str(c).lower() for c in g.columns]\n",
    "    c = g[\"close\"].astype(float)\n",
    "\n",
    "    ma20 = c.rolling(20, min_periods=20).mean()\n",
    "    sd20 = c.rolling(20, min_periods=20).std(ddof=0)\n",
    "    bbw20 = (4.0 * sd20) / ma20.replace(0.0, np.nan)  # normalized width\n",
    "\n",
    "    # Rolling 20th percentile over 120 bars\n",
    "    # Note: rolling(...).quantile(q) is vectorized and avoids look-ahead.\n",
    "    thresh = bbw20.rolling(120, min_periods=120).quantile(0.20, interpolation=\"linear\")\n",
    "\n",
    "    flag = (bbw20 <= thresh).astype(int).fillna(0)\n",
    "    s = pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "d68d118da7f723b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: band_gauss_lower_dist_20_2\n",
    "FEATURE_CODE = \"band_gauss_lower_dist_20_2\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Gaussian Lower Band Distance (20, 2σ)\n",
    "    Description:\n",
    "      Relative distance from close to the lower Gaussian band:\n",
    "        lower = SMA(close,20) - 2 * std(close,20, ddof=0)\n",
    "      (This is the common Bollinger lower band with 20 periods, 2 standard deviations.)\n",
    "    Formula / method (brief):\n",
    "      ma20 = rolling mean(close,20); sd20 = rolling std(close,20) with ddof=0\n",
    "      lower = ma20 - 2 * sd20\n",
    "      dist = (close - lower) / close\n",
    "    Input/Output/Constraints:\n",
    "      Standard; vectorized; no look-ahead.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    ma20 = g[\"close\"].rolling(20, min_periods=20).mean()\n",
    "    sd20 = g[\"close\"].rolling(20, min_periods=20).std(ddof=0)\n",
    "    lower = ma20 - 2 * sd20\n",
    "\n",
    "    s = (g[\"close\"].astype(float) - lower) / g[\"close\"].astype(float)\n",
    "    s = s.astype(float); s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "f8c7c24b105eda5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: fib_extension_near_1_272\n",
    "FEATURE_CODE = \"fib_extension_near_1_272\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fibonacci Extension Near 1.272\n",
    "    Description:\n",
    "      Flags if the close is near the Fibonacci extension level of 1.272.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      fib_1_272 = (high - low) * 1.272 + low\n",
    "      flag = 1 if abs(close - fib_1_272) / close <= ε else 0\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].rolling(2, min_periods=2).max()\n",
    "    low = g[\"low\"].rolling(2, min_periods=2).min()\n",
    "\n",
    "    fib_1_272 = (high - low) * 1.272 + low\n",
    "\n",
    "    epsilon = 0.01  # proximity range, you can adjust this value\n",
    "    flag = (abs(g[\"close\"] - fib_1_272) / g[\"close\"] <= epsilon).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "dae1109980d86ba3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: fib_extension_near_1_618\n",
    "FEATURE_CODE = \"fib_extension_near_1_618\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fibonacci Extension Near 1.618\n",
    "    Description:\n",
    "      Flags if the close is near the Fibonacci extension level of 1.618.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      fib_1_618 = (high - low) * 1.618 + low\n",
    "      flag = 1 if abs(close - fib_1_618) / close <= ε else 0\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].rolling(2, min_periods=2).max()\n",
    "    low = g[\"low\"].rolling(2, min_periods=2).min()\n",
    "\n",
    "    fib_1_618 = (high - low) * 1.618 + low\n",
    "\n",
    "    epsilon = 0.01  # proximity range, you can adjust this value\n",
    "    flag = (abs(g[\"close\"] - fib_1_618) / g[\"close\"] <= epsilon).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "678fc849a39a5303"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: fib_retracement_near_0_500\n",
    "FEATURE_CODE = \"fib_retracement_near_0_500\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fibonacci Retracement Near 0.500\n",
    "    Description:\n",
    "      Flags if the close is near the Fibonacci retracement level of 50%.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      fib_0_500 = (high - low) * 0.500 + low\n",
    "      flag = 1 if abs(close - fib_0_500) / close <= ε else 0\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].rolling(2, min_periods=2).max()\n",
    "    low = g[\"low\"].rolling(2, min_periods=2).min()\n",
    "\n",
    "    fib_0_500 = (high - low) * 0.500 + low\n",
    "\n",
    "    epsilon = 0.01  # proximity range, you can adjust this value\n",
    "    flag = (abs(g[\"close\"] - fib_0_500) / g[\"close\"] <= epsilon).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "995553acb2632391"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: fib_retracement_near_0_618\n",
    "FEATURE_CODE = \"fib_retracement_near_0_618\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fibonacci Retracement Near 0.618\n",
    "    Description:\n",
    "      Flags if the close is near the Fibonacci retracement level of 61.8%.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      fib_0_618 = (high - low) * 0.618 + low\n",
    "      flag = 1 if abs(close - fib_0_618) / close <= ε else 0\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].rolling(2, min_periods=2).max()\n",
    "    low = g[\"low\"].rolling(2, min_periods=2).min()\n",
    "\n",
    "    fib_0_618 = (high - low) * 0.618 + low\n",
    "\n",
    "    epsilon = 0.01  # proximity range, you can adjust this value\n",
    "    flag = (abs(g[\"close\"] - fib_0_618) / g[\"close\"] <= epsilon).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "5dc22e108cf35f2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: liq_daily_zone_touch_flag_1d\n",
    "FEATURE_CODE = \"liq_daily_zone_touch_flag_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Liquidity Zone Daily Touch Flag (1d)\n",
    "    Description:\n",
    "      Flags 1 if the close touches the liquidity zone (high-low range) of the prior day.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      daily_high = high of previous day\n",
    "      daily_low = low of previous day\n",
    "      flag = 1 if close_t is between (daily_low - ε) and (daily_high + ε)\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high_prev = g[\"high\"].shift(1)\n",
    "    low_prev = g[\"low\"].shift(1)\n",
    "\n",
    "    epsilon = 0.01  # proximity range\n",
    "    flag = ((g[\"close\"] >= low_prev - epsilon) & (g[\"close\"] <= high_prev + epsilon)).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "f66fa189ed5ede0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: liq_weekly_zone_touch_flag_1w\n",
    "FEATURE_CODE = \"liq_weekly_zone_touch_flag_1w\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Liquidity Zone Weekly Touch Flag (1w)\n",
    "    Description:\n",
    "      Flags 1 if the close touches the liquidity zone (high-low range) of the prior week.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      weekly_high = high of previous week\n",
    "      weekly_low = low of previous week\n",
    "      flag = 1 if close_t is between (weekly_low - ε) and (weekly_high + ε)\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high_prev = g[\"high\"].shift(5)  # Assumes 5 trading days per week\n",
    "    low_prev = g[\"low\"].shift(5)  # Assumes 5 trading days per week\n",
    "\n",
    "    epsilon = 0.01  # proximity range\n",
    "    flag = ((g[\"close\"] >= low_prev - epsilon) & (g[\"close\"] <= high_prev + epsilon)).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "f5b6ebb96d6cabed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: liq_zone_strength_50\n",
    "FEATURE_CODE = \"liq_zone_strength_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Liquidity Zone Strength (50)\n",
    "    Description:\n",
    "      Measures the relative liquidity strength (volume density) within a 50-bar window.\n",
    "      Higher liquidity strength is associated with higher trading volumes within a given range.\n",
    "    Formula / method (brief):\n",
    "      - liquidity_strength = sum(volume within range) / (high - low) over the last 50 bars\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"]\n",
    "    low = g[\"low\"]\n",
    "    volume = g[\"volume\"]\n",
    "\n",
    "    liquidity_strength = (volume * (high - low)).rolling(50, min_periods=50).sum() / (high - low).rolling(50, min_periods=50).sum()\n",
    "\n",
    "    s = liquidity_strength.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "dce60e12a1b06322"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: liq_zone_touch_flag_50\n",
    "FEATURE_CODE = \"liq_zone_touch_flag_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Liquidity Zone Touch Flag (50)\n",
    "    Description:\n",
    "      Flags 1 if the close touches the liquidity zone (high-low range) over the last 50 bars.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      liquidity_zone = high-low for the last 50 bars\n",
    "      flag = 1 if close_t is within liquidity_zone (+ε) and (-ε)\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"]\n",
    "    low = g[\"low\"]\n",
    "\n",
    "    liquidity_zone_high = high.rolling(50, min_periods=50).max()\n",
    "    liquidity_zone_low = low.rolling(50, min_periods=50).min()\n",
    "\n",
    "    epsilon = 0.01  # proximity range\n",
    "    flag = ((g[\"close\"] >= liquidity_zone_low - epsilon) & (g[\"close\"] <= liquidity_zone_high + epsilon)).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "5f4fd2773841cd8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: price_prev_high_dist_1\n",
    "FEATURE_CODE = \"price_prev_high_dist_1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Price Previous High Distance (1 bar)\n",
    "    Description:\n",
    "      Flags 1 if the close is close to the high of the previous bar.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      prev_high = high of previous bar\n",
    "      flag = 1 if abs(close_t - prev_high) / close_t <= ε else 0\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    prev_high = g[\"high\"].shift(1)\n",
    "\n",
    "    epsilon = 0.01  # proximity range\n",
    "    flag = (abs(g[\"close\"] - prev_high) / g[\"close\"] <= epsilon).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "f6ee0fa0f9b0c2d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: price_prev_low_dist_1\n",
    "FEATURE_CODE = \"price_prev_low_dist_1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Price Previous Low Distance (1 bar)\n",
    "    Description:\n",
    "      Flags 1 if the close is close to the low of the previous bar.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      prev_low = low of previous bar\n",
    "      flag = 1 if abs(close_t - prev_low) / close_t <= ε else 0\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    prev_low = g[\"low\"].shift(1)\n",
    "\n",
    "    epsilon = 0.01  # proximity range\n",
    "    flag = (abs(g[\"close\"] - prev_low) / g[\"close\"] <= epsilon).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "2126b0d945f521c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: session_asian_high_dist_1d\n",
    "FEATURE_CODE = \"session_asian_high_dist_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Session Asian High Distance (1d)\n",
    "    Description:\n",
    "      Flags 1 if the close is close to the high of the previous day's Asian session.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      asian_high = high of previous day's Asian session\n",
    "      flag = 1 if abs(close_t - asian_high) / close_t <= ε else 0\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    # Assuming Asian session high is the high of the first few hours of the day,\n",
    "    # we'll calculate it from the first 4 hours for this example.\n",
    "    asian_session = g.between_time('00:00', '04:00')  # Adjust based on Asian session time\n",
    "    asian_high = asian_session[\"high\"].max()\n",
    "\n",
    "    flag = (abs(g[\"close\"] - asian_high) / g[\"close\"] <= 0.01).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "a754bbfc3b25f437"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: session_asian_low_dist_1d\n",
    "FEATURE_CODE = \"session_asian_low_dist_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Session Asian Low Distance (1d)\n",
    "    Description:\n",
    "      Flags 1 if the close is close to the low of the previous day's Asian session.\n",
    "      Proximity is determined within a small range (ε = 0.01).\n",
    "    Formula / method (brief):\n",
    "      asian_low = low of previous day's Asian session\n",
    "      flag = 1 if abs(close_t - asian_low) / close_t <= ε else 0\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    # Assuming Asian session low is the low of the first few hours of the day,\n",
    "    # we'll calculate it from the first 4 hours for this example.\n",
    "    asian_session = g.between_time('00:00', '04:00')  # Adjust based on Asian session time\n",
    "    asian_low = asian_session[\"low\"].min()\n",
    "\n",
    "    flag = (abs(g[\"close\"] - asian_low) / g[\"close\"] <= 0.01).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "fb53428a3b66097c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: mom_volume_trend_div_flag_20\n",
    "FEATURE_CODE = \"mom_volume_trend_div_flag_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Volume and Trend Divergence Flag (20)\n",
    "    Description:\n",
    "      Flags if there is a divergence between price trend and volume trend.\n",
    "      Price goes up/down while volume behaves oppositely, indicating a divergence.\n",
    "    Formula / method (brief):\n",
    "      - Calculate rolling mean of close and volume over 20 periods.\n",
    "      - Flag 1 if price and volume trends diverge (one goes up, the other down).\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    price_rolling_mean = g[\"close\"].rolling(20).mean()\n",
    "    volume_rolling_mean = g[\"volume\"].rolling(20).mean()\n",
    "\n",
    "    # Identify divergence\n",
    "    price_up = g[\"close\"] > price_rolling_mean\n",
    "    volume_up = g[\"volume\"] > volume_rolling_mean\n",
    "\n",
    "    divergence = (price_up != volume_up).astype(int)\n",
    "\n",
    "    s = pd.Series(divergence, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "7ca61589736d3d32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: trendline_break_rsi_14\n",
    "FEATURE_CODE = \"trendline_break_rsi_14\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    RSI Trendline Breakout Flag (14)\n",
    "    Description:\n",
    "      Flags 1 if RSI(14) breaks through its trendline, indicating a breakout.\n",
    "    Formula / method (brief):\n",
    "      - Calculate the 14-period RSI.\n",
    "      - Detect trendline breakout (RSI crosses its rolling mean).\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    rsi_14 = g[\"close\"].rolling(14).apply(lambda x: 100 - (100 / (1 + (x.diff().clip(0).mean() / x.diff().clip(None).mean()))))\n",
    "\n",
    "    rsi_trendline = rsi_14.rolling(14).mean()\n",
    "\n",
    "    breakout = (rsi_14 > rsi_trendline).astype(int)\n",
    "\n",
    "    s = pd.Series(breakout, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "7f895316578af972"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: break_prev_low_flag_1\n",
    "FEATURE_CODE = \"break_prev_low_flag_1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Break Previous Low Flag (1 bar)\n",
    "    Description:\n",
    "      Flags 1 if the current close is lower than the low of the previous bar, indicating a breakdown.\n",
    "    Formula / method (brief):\n",
    "      - Check if close_t < low_{t-1}.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    prev_low = g[\"low\"].shift(1)\n",
    "    flag = (g[\"close\"] < prev_low).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "15be9fecde802299"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: break_prev_high_flag_1\n",
    "FEATURE_CODE = \"break_prev_high_flag_1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Break Previous High Flag (1 bar)\n",
    "    Description:\n",
    "      Flags 1 if the current close is higher than the high of the previous bar, indicating a breakout.\n",
    "    Formula / method (brief):\n",
    "      - Check if close_t > high_{t-1}.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    prev_high = g[\"high\"].shift(1)\n",
    "    flag = (g[\"close\"] > prev_high).astype(int)\n",
    "\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "e9bc1679995bce00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: fvg_creation_flag_1\n",
    "FEATURE_CODE = \"fvg_creation_flag_1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fair Value Gap Creation Flag (1 bar)\n",
    "    Description:\n",
    "      Flags 1 if a fair value gap (FVG) is created, defined as a large price movement gap.\n",
    "    Formula / method (brief):\n",
    "      - A gap is formed when the open price is significantly different from the close price.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    price_gap = abs(g[\"open\"] - g[\"close\"].shift(1))\n",
    "\n",
    "    # Set threshold for large gap (FVG), e.g., 0.01 or any custom logic\n",
    "    threshold = 0.01\n",
    "\n",
    "    fvg_flag = (price_gap > threshold).astype(int)\n",
    "\n",
    "    s = pd.Series(fvg_flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "f6869ae72a31ca2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: breaker_block_distance_20\n",
    "FEATURE_CODE = \"breaker_block_distance_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Breaker Block Distance (20)\n",
    "    Idea:\n",
    "      Approximate distance from current close to a recent \"breaker\" level\n",
    "      using 20-bar rolling extremes.\n",
    "      - If short-term direction is up -> use rolling 20-bar high as breaker\n",
    "      - If short-term direction is down -> use rolling 20-bar low\n",
    "      Distance is normalized by close.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    close = g[\"close\"].astype(float)\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "\n",
    "    dir_sign = np.sign(close - close.shift(1)).fillna(0.0)\n",
    "    rh = high.rolling(20, min_periods=20).max()\n",
    "    rl = low.rolling(20, min_periods=20).min()\n",
    "\n",
    "    breaker_level = np.where(dir_sign >= 0, rh.shift(1), rl.shift(1))\n",
    "    breaker_level = pd.Series(breaker_level, index=g.index)\n",
    "\n",
    "    dist = (close - breaker_level) / close.replace(0.0, np.nan)\n",
    "    s = dist.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "521b1bd20aaf728f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: breaker_retest_flag_20\n",
    "FEATURE_CODE = \"breaker_retest_flag_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Breaker Retest Flag (20)\n",
    "    Approximation:\n",
    "      Flag == 1 when close is near a 20-bar extreme\n",
    "      (interpreted as a retest of a prior breaker zone).\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    close = g[\"close\"].astype(float)\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "\n",
    "    rh = high.rolling(20, min_periods=20).max()\n",
    "    rl = low.rolling(20, min_periods=20).min()\n",
    "\n",
    "    tol = 0.001  # 0.1% tolerance around extremum\n",
    "    near_high = (np.abs(close - rh) / close.replace(0.0, np.nan)) <= tol\n",
    "    near_low = (np.abs(close - rl) / close.replace(0.0, np.nan)) <= tol\n",
    "\n",
    "    flag = (near_high | near_low).astype(int)\n",
    "    s = pd.Series(flag, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "5c3ea538065b67f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: candle_engulf_strength_5\n",
    "FEATURE_CODE = \"candle_engulf_strength_5\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Candle Engulf Strength (5)\n",
    "    Measures strength of engulfing patterns over a 5-bar context:\n",
    "      - True engulf if body direction flips and current body fully contains previous body.\n",
    "      - Strength = current body / max body in last 5 bars (0..1).\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    o = g[\"open\"].astype(float)\n",
    "    c = g[\"close\"].astype(float)\n",
    "    h = g[\"high\"].astype(float)\n",
    "    l = g[\"low\"].astype(float)\n",
    "\n",
    "    body = (c - o).abs()\n",
    "    prev_body = body.shift(1)\n",
    "    dir_curr = np.sign(c - o)\n",
    "    dir_prev = np.sign(c.shift(1) - o.shift(1))\n",
    "\n",
    "    engulf_range = (h >= h.shift(1)) & (l <= l.shift(1))\n",
    "    opposite_dir = (dir_curr * dir_prev) < 0\n",
    "    bigger_body = body > prev_body\n",
    "\n",
    "    engulf_flag = (engulf_range & opposite_dir & bigger_body).astype(int)\n",
    "    max_body_5 = body.rolling(5, min_periods=1).max()\n",
    "\n",
    "    strength = np.where(engulf_flag == 1, body / max_body_5.replace(0.0, np.nan), 0.0)\n",
    "    s = pd.Series(strength, index=g.index, name=FEATURE_CODE).astype(float)\n",
    "    return s\n"
   ],
   "id": "ecd7c31d9e313bc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: displacement_strength_10\n",
    "FEATURE_CODE = \"displacement_strength_10\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Displacement Strength (10)\n",
    "    Idea:\n",
    "      Measures impulsiveness of price move vs average volatility:\n",
    "      strength = |close - close[-1]| / ATR(10)\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    c = g[\"close\"].astype(float)\n",
    "    h = g[\"high\"].astype(float)\n",
    "    l = g[\"low\"].astype(float)\n",
    "    prev_c = c.shift(1)\n",
    "\n",
    "    tr = (h - l).combine((h - prev_c).abs(), np.maximum).combine((l - prev_c).abs(), np.maximum)\n",
    "    atr = tr.rolling(10, min_periods=1).mean().replace(0.0, np.nan)\n",
    "\n",
    "    s = (c - prev_c).abs() / atr\n",
    "    s = s.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "66a7e824d15ee9ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: ent_perm_close_30\n",
    "FEATURE_CODE = \"ent_perm_close_30\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Permutation-like Entropy of Close (30)\n",
    "    Approximation:\n",
    "      Uses Shannon entropy of rank-discretized closes over a 30-bar window.\n",
    "      Normalized to [0,1].\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    c = g[\"close\"].astype(float)\n",
    "\n",
    "    def window_entropy(x: np.ndarray) -> float:\n",
    "        if len(x) < 3:\n",
    "            return np.nan\n",
    "        # Rank discretization\n",
    "        ranks = pd.Series(x).rank(method=\"average\").values\n",
    "        # Bin into 5 quantile-buckets\n",
    "        qs = np.quantile(ranks, [0.2, 0.4, 0.6, 0.8])\n",
    "        bins = np.digitize(ranks, qs)\n",
    "        counts = np.bincount(bins, minlength=5).astype(float)\n",
    "        p = counts / counts.sum() if counts.sum() > 0 else counts\n",
    "        p = p[p > 0]\n",
    "        if len(p) == 0:\n",
    "            return np.nan\n",
    "        ent = -np.sum(p * np.log(p))\n",
    "        # Max entropy with 5 bins\n",
    "        ent_norm = ent / np.log(5.0)\n",
    "        return float(ent_norm)\n",
    "\n",
    "    s = c.rolling(30, min_periods=10).apply(window_entropy, raw=True)\n",
    "    s = s.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "d469fc08dc57e48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: equal_highs_tightness_20\n",
    "FEATURE_CODE = \"equal_highs_tightness_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Equal Highs Tightness (20)\n",
    "    Measures how tight 20-bar highs are:\n",
    "      tightness = (max_high_20 - min_high_20) / close\n",
    "      Lower values = tighter equal-highs zone.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    h = g[\"high\"].astype(float)\n",
    "    c = g[\"close\"].astype(float)\n",
    "\n",
    "    max_h = h.rolling(20, min_periods=5).max()\n",
    "    min_h = h.rolling(20, min_periods=5).min()\n",
    "\n",
    "    tightness = (max_h - min_h) / c.replace(0.0, np.nan)\n",
    "    s = tightness.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "7352aa5afc052aa8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: equal_lows_tightness_20\n",
    "FEATURE_CODE = \"equal_lows_tightness_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Equal Lows Tightness (20)\n",
    "    Same idea as highs, for lows:\n",
    "      tightness = (max_low_20 - min_low_20) / close\n",
    "      Lower values = tighter support zone.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    l = g[\"low\"].astype(float)\n",
    "    c = g[\"close\"].astype(float)\n",
    "\n",
    "    max_l = l.rolling(20, min_periods=5).max()\n",
    "    min_l = l.rolling(20, min_periods=5).min()\n",
    "\n",
    "    tightness = (max_l - min_l) / c.replace(0.0, np.nan)\n",
    "    s = tightness.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "c849bb6721b11033"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: filt_dema_20\n",
    "FEATURE_CODE = \"filt_dema_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Double EMA Filter (20)\n",
    "    DEMA(20) = 2 * EMA(20) - EMA(EMA(20))\n",
    "    Causal, no look-ahead smoothing of close.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    c = g[\"close\"].astype(float)\n",
    "\n",
    "    ema1 = c.ewm(span=20, adjust=False).mean()\n",
    "    ema2 = ema1.ewm(span=20, adjust=False).mean()\n",
    "    dema = 2.0 * ema1 - ema2\n",
    "\n",
    "    s = dema.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "b9c2f4b6c4c80fb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: filt_gauss_close_20\n",
    "FEATURE_CODE = \"filt_gauss_close_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Gaussian Weighted Moving Average (20, causal)\n",
    "    Uses a backward-looking Gaussian kernel of length 20 on closes.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    c = g[\"close\"].astype(float)\n",
    "\n",
    "    window = 20\n",
    "    idx = np.arange(window)\n",
    "    # center at current bar (0) and decay into the past\n",
    "    sigma = window / 4.0\n",
    "    weights = np.exp(-0.5 * (idx / sigma) ** 2)\n",
    "    weights = weights[::-1]  # bigger weight on most recent\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    def gauss(x: np.ndarray) -> float:\n",
    "        if len(x) < window:\n",
    "            w = weights[-len(x):]\n",
    "        else:\n",
    "            w = weights\n",
    "        return float(np.sum(x * w))\n",
    "\n",
    "    s = c.rolling(window, min_periods=3).apply(gauss, raw=True)\n",
    "    s = s.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "6c309a60224d97e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: filt_savgol_11_3\n",
    "FEATURE_CODE = \"filt_savgol_11_3\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Savitzky-Golay-like Filter (window=11, poly=3, causal)\n",
    "    Approximates a SG(11,3) on the last 11 closes via polynomial regression.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    c = g[\"close\"].astype(float)\n",
    "\n",
    "    def sg_causal(x: np.ndarray) -> float:\n",
    "        n = len(x)\n",
    "        if n < 5:\n",
    "            return float(x[-1])\n",
    "        # Fit poly of degree 3 on indices [0..n-1], return fitted value at last index\n",
    "        xs = np.arange(n, dtype=float)\n",
    "        coeffs = np.polyfit(xs, x, deg=3)\n",
    "        val = np.polyval(coeffs, xs[-1])\n",
    "        return float(val)\n",
    "\n",
    "    s = c.rolling(11, min_periods=5).apply(sg_causal, raw=True)\n",
    "    s = s.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "f307c586b5577c2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: fvg_fill_ratio_30\n",
    "FEATURE_CODE = \"fvg_fill_ratio_30\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    FVG Fill Ratio (30) - causal approximation\n",
    "    Idea:\n",
    "      Measure how large the current 2-bar \"gap\" is vs the max gap in last 30 bars.\n",
    "      Smaller current gap -> higher fill ratio.\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "    h = g[\"high\"].astype(float)\n",
    "    l = g[\"low\"].astype(float)\n",
    "\n",
    "    # Simple 2-bar FVG-style gap\n",
    "    prev_h = h.shift(1)\n",
    "    prev_l = l.shift(1)\n",
    "    gap_up = np.maximum(0.0, l - prev_h)    # bullish gap\n",
    "    gap_dn = np.maximum(0.0, prev_l - h)    # bearish gap\n",
    "    gap = gap_up + gap_dn\n",
    "\n",
    "    max_gap_30 = gap.rolling(30, min_periods=1).max().replace(0.0, np.nan)\n",
    "    ratio = 1.0 - (gap / max_gap_30)\n",
    "    s = ratio.clip(lower=0.0, upper=1.0).astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "7f3eec75d4b8870c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: internal_range_shift_20\n",
    "FEATURE_CODE = \"internal_range_shift_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Internal Range Shift (20)\n",
    "    Position of close inside 20-bar range, differenced:\n",
    "      pos_t = (close - low20) / (high20 - low20)\n",
    "      shift = pos_t - pos_{t-1}\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    c = g[\"close\"].astype(float)\n",
    "    h = g[\"high\"].astype(float)\n",
    "    l = g[\"low\"].astype(float)\n",
    "\n",
    "    hi20 = h.rolling(20, min_periods=5).max()\n",
    "    lo20 = l.rolling(20, min_periods=5).min()\n",
    "    rng = (hi20 - lo20).replace(0.0, np.nan)\n",
    "\n",
    "    pos = (c - lo20) / rng\n",
    "    shift = pos - pos.shift(1)\n",
    "\n",
    "    s = shift.astype(float)\n",
    "    s.name = FEATURE_CODE\n",
    "    return s\n"
   ],
   "id": "ee2e22ba440871f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: liquidity_grab_efficiency_10\n",
    "FEATURE_CODE = \"liquidity_grab_efficiency_10\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Liquidity Grab Efficiency (10-bar lookback)\n",
    "\n",
    "    Logic:\n",
    "      Detects liquidity grabs (sweeps) above/below prior highs/lows.\n",
    "        - Upward grab: current high > max(high[1..10]) AND close < previous max\n",
    "        - Downward grab: current low < min(low[1..10]) AND close > previous min\n",
    "\n",
    "      Efficiency is measured as:\n",
    "          wick_outside_range / full_candle_range\n",
    "\n",
    "      The output is between 0 and 1.\n",
    "      Zero means no liquidity grab or no efficiency.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "    open_ = g[\"open\"].astype(float)\n",
    "\n",
    "    lookback = 10\n",
    "\n",
    "    # Prior N-bar extremes (shifted to avoid using current bar)\n",
    "    prior_high = high.rolling(lookback, min_periods=lookback).max().shift(1)\n",
    "    prior_low  = low .rolling(lookback, min_periods=lookback).min().shift(1)\n",
    "\n",
    "    # Conditions for sweeps\n",
    "    up_grab   = (high > prior_high) & (close < prior_high)\n",
    "    down_grab = (low  < prior_low ) & (close > prior_low)\n",
    "\n",
    "    # Candle range\n",
    "    tr = (high - low).replace(0.0, np.nan)\n",
    "\n",
    "    upper_body = np.maximum(open_, close)\n",
    "    lower_body = np.minimum(open_, close)\n",
    "\n",
    "    wick_above = (high - upper_body).clip(lower=0.0)\n",
    "    wick_below = (lower_body - low).clip(lower=0.0)\n",
    "\n",
    "    eff_up   = np.where(up_grab,   wick_above / tr, 0.0)\n",
    "    eff_down = np.where(down_grab, wick_below / tr, 0.0)\n",
    "\n",
    "    eff = np.nan_to_num(eff_up + eff_down)\n",
    "\n",
    "    return pd.Series(eff, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "12fe7fc44f05bcdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: liquidity_rebuild_speed_20\n",
    "FEATURE_CODE = \"liquidity_rebuild_speed_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Liquidity Rebuild Speed (20-bar window)\n",
    "\n",
    "    Idea:\n",
    "      Measures how fast price returns toward the center of its 20-bar range.\n",
    "\n",
    "      Steps:\n",
    "        1. Compute high20, low20, and mid20 of the last 20 bars.\n",
    "        2. Normalize distance:\n",
    "             dist_norm = |close - mid20| / (high20 - low20)\n",
    "        3. Speed is the reduction in this distance over 5 bars:\n",
    "             speed = dist_norm.shift(5) - dist_norm\n",
    "\n",
    "      Positive values → price is reverting back toward liquidity zones.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    win = 20\n",
    "    lag = 5\n",
    "\n",
    "    high20 = high.rolling(win).max()\n",
    "    low20  = low .rolling(win).min()\n",
    "    mid20  = (high20 + low20) / 2\n",
    "    range20 = (high20 - low20).replace(0.0, np.nan)\n",
    "\n",
    "    dist_norm = (close - mid20).abs() / range20\n",
    "    dist_norm = dist_norm.clip(0.0, 1.0)\n",
    "\n",
    "    speed = dist_norm.shift(lag) - dist_norm\n",
    "    speed = speed.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return pd.Series(speed, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "4ad6b5c1699800ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: micro_range_stack_count_20\n",
    "FEATURE_CODE = \"micro_range_stack_count_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Micro Range Stack Count (20-bar rolling)\n",
    "\n",
    "    Logic:\n",
    "      - Compute true range of each candle.\n",
    "      - Determine micro-ranges by comparing TR to the rolling 25th percentile\n",
    "        of the last 100 TR values.\n",
    "      - A micro-range is TR <= threshold.\n",
    "      - This feature returns the rolling 20-bar sum of micro-range flags.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "\n",
    "    # True range\n",
    "    tr = (high - low).abs()\n",
    "\n",
    "    # Micro-range threshold (25th percentile)\n",
    "    threshold = tr.rolling(100, min_periods=30).quantile(0.25)\n",
    "\n",
    "    micro_flag = (tr <= threshold).astype(float).fillna(0.0)\n",
    "\n",
    "    # Count of micro ranges over last 20 bars\n",
    "    count = micro_flag.rolling(20, min_periods=1).sum()\n",
    "\n",
    "    return pd.Series(count, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "13b19de95124b3ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: orderblock_freshness_score_50\n",
    "FEATURE_CODE = \"orderblock_freshness_score_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Orderblock Freshness Score (50-bar proxy)\n",
    "\n",
    "    Idea:\n",
    "      A simple proxy for \"freshness\" of orderblock-like zones.\n",
    "\n",
    "      Steps:\n",
    "        - Compute 50-bar high and 50-bar low.\n",
    "        - Compute the candle’s distance to the nearest extreme (high50 or low50).\n",
    "        - Normalize the distance by the 50-bar range.\n",
    "        - Score = 1 - normalized_distance (clamped to [0,1])\n",
    "\n",
    "      The closer price is to a recent extreme, the \"fresher\" the zone.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    win = 50\n",
    "\n",
    "    high50 = high.rolling(win).max()\n",
    "    low50  = low .rolling(win).min()\n",
    "    range50 = (high50 - low50).replace(0.0, np.nan)\n",
    "\n",
    "    dist_high = (close - high50).abs()\n",
    "    dist_low  = (close - low50).abs()\n",
    "\n",
    "    nearest_dist = pd.concat([dist_high, dist_low], axis=1).min(axis=1)\n",
    "\n",
    "    base = nearest_dist / range50\n",
    "    score = (1.0 - base).clip(0.0, 1.0).fillna(0.0)\n",
    "\n",
    "    return pd.Series(score, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "5e313f43525b7e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: pivot_confluence_score_1d\n",
    "FEATURE_CODE = \"pivot_confluence_score_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Pivot Confluence Score (classic pivots from previous day)\n",
    "\n",
    "    Requirements:\n",
    "        Index must be a DatetimeIndex.\n",
    "\n",
    "    Logic:\n",
    "        - Compute previous day's OHLC.\n",
    "        - Compute classic pivot levels:\n",
    "             PP, R1, S1, R2, S2\n",
    "        - For each intraday bar, compute normalized distance:\n",
    "             dist_norm = |close - level| / (prev_day_range)\n",
    "        - Confluence score = Σ exp(-alpha * dist_norm)\n",
    "          (Higher score = stronger confluence around pivots)\n",
    "\n",
    "    Output is continuous, usually between 0 and ~5.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    if not isinstance(g.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"pivot_confluence_score_1d requires a DatetimeIndex.\")\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    # Extract date for grouping\n",
    "    dates = g.index.normalize()\n",
    "\n",
    "    # Daily OHLC\n",
    "    daily = pd.DataFrame({\"high\": high, \"low\": low, \"close\": close})\n",
    "    daily_ohlc = daily.groupby(dates).agg({\"high\": \"max\", \"low\": \"min\", \"close\": \"last\"})\n",
    "\n",
    "    prev = daily_ohlc.shift(1)\n",
    "\n",
    "    prev_high  = prev[\"high\"].reindex(dates).values\n",
    "    prev_low   = prev[\"low\"] .reindex(dates).values\n",
    "    prev_close = prev[\"close\"].reindex(dates).values\n",
    "\n",
    "    prev_high  = pd.Series(prev_high,  index=g.index)\n",
    "    prev_low   = pd.Series(prev_low,   index=g.index)\n",
    "    prev_close = pd.Series(prev_close, index=g.index)\n",
    "\n",
    "    prev_range = (prev_high - prev_low).replace(0.0, np.nan)\n",
    "\n",
    "    PP = (prev_high + prev_low + prev_close) / 3\n",
    "    R1 = 2*PP - prev_low\n",
    "    S1 = 2*PP - prev_high\n",
    "    R2 = PP + (prev_high - prev_low)\n",
    "    S2 = PP - (prev_high - prev_low)\n",
    "\n",
    "    def norm_dist(level):\n",
    "        d = (close - level).abs() / prev_range\n",
    "        return d.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    dist_levels = [\n",
    "        norm_dist(PP),\n",
    "        norm_dist(R1),\n",
    "        norm_dist(S1),\n",
    "        norm_dist(R2),\n",
    "        norm_dist(S2),\n",
    "    ]\n",
    "\n",
    "    alpha = 5.0\n",
    "\n",
    "    score = sum(np.exp(-alpha * d.fillna(99)) for d in dist_levels)\n",
    "    score = pd.Series(score, index=g.index).fillna(0.0)\n",
    "\n",
    "    return score.rename(FEATURE_CODE)\n"
   ],
   "id": "c8f4ae96c8734e9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: premium_discount_balance_50\n",
    "FEATURE_CODE = \"premium_discount_balance_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Premium–Discount Balance (50-bar window)\n",
    "\n",
    "    Logic:\n",
    "      - Compute 50-bar rolling high and low.\n",
    "      - Midpoint: mid50 = (high50 + low50) / 2\n",
    "      - For each bar:\n",
    "          premium_flag  = 1 if close > mid50\n",
    "          discount_flag = 1 if close < mid50\n",
    "      - Feature = (sum(premium_flag) - sum(discount_flag)) / 50\n",
    "        over the last 50 bars.\n",
    "\n",
    "      Interpretation:\n",
    "        +1 → closes mostly in premium\n",
    "        -1 → closes mostly in discount\n",
    "         0 → balanced.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    win = 50\n",
    "\n",
    "    high50 = high.rolling(win).max()\n",
    "    low50  = low .rolling(win).min()\n",
    "    mid50  = (high50 + low50) / 2.0\n",
    "\n",
    "    premium_flag  = (close > mid50).astype(float)\n",
    "    discount_flag = (close < mid50).astype(float)\n",
    "\n",
    "    premium_count  = premium_flag.rolling(win, min_periods=1).sum()\n",
    "    discount_count = discount_flag.rolling(win, min_periods=1).sum()\n",
    "\n",
    "    balance = (premium_count - discount_count) / float(win)\n",
    "    balance = balance.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return pd.Series(balance.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "2b88d7f205daef22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: prior_range_overlap_ratio_50\n",
    "FEATURE_CODE = \"prior_range_overlap_ratio_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Prior Range Overlap Ratio (50-bar window)\n",
    "\n",
    "    Logic:\n",
    "      For each bar:\n",
    "        - current range:  [low50, high50]   from last 50 bars including current\n",
    "        - prior range:    [low50_prev, high50_prev] from last 50 bars ending at previous bar\n",
    "        - intersection = max(0, min(high50, high50_prev) - max(low50, low50_prev))\n",
    "        - union        = max(0, max(high50, high50_prev) - min(low50, low50_prev))\n",
    "        - ratio        = intersection / union\n",
    "\n",
    "      Output is between 0 and 1 (0 = no overlap, 1 = identical ranges).\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "\n",
    "    win = 50\n",
    "\n",
    "    high50 = high.rolling(win).max()\n",
    "    low50  = low .rolling(win).min()\n",
    "\n",
    "    high50_prev = high50.shift(1)\n",
    "    low50_prev  = low50.shift(1)\n",
    "\n",
    "    # Intersection\n",
    "    inter_low  = np.maximum(low50, low50_prev)\n",
    "    inter_high = np.minimum(high50, high50_prev)\n",
    "    intersection = (inter_high - inter_low).clip(lower=0.0)\n",
    "\n",
    "    # Union\n",
    "    union_low  = np.minimum(low50, low50_prev)\n",
    "    union_high = np.maximum(high50, high50_prev)\n",
    "    union = (union_high - union_low).clip(lower=0.0)\n",
    "\n",
    "    ratio = intersection / union.replace(0.0, np.nan)\n",
    "    ratio = ratio.clip(0.0, 1.0).fillna(0.0)\n",
    "\n",
    "    return pd.Series(ratio.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "7937156fe710d102"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: range_rotation_index_20\n",
    "FEATURE_CODE = \"range_rotation_index_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Range Rotation Index (20-bar window)\n",
    "\n",
    "    Logic:\n",
    "      - Compute 20-bar rolling high and low.\n",
    "      - mid20 = (high20 + low20) / 2\n",
    "      - For each bar:\n",
    "          delta_mid = mid20 - mid20.shift(1)\n",
    "          sign_rot  = sign(delta_mid) in {-1, 0, +1}\n",
    "      - Feature = rolling mean of sign_rot over 20 bars.\n",
    "\n",
    "      Interpretation:\n",
    "        +1 → midpoint mostly rotating upward\n",
    "        -1 → midpoint mostly rotating downward\n",
    "         0 → balanced / choppy.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "\n",
    "    win = 20\n",
    "\n",
    "    high20 = high.rolling(win).max()\n",
    "    low20  = low .rolling(win).min()\n",
    "    mid20  = (high20 + low20) / 2.0\n",
    "\n",
    "    delta_mid = mid20 - mid20.shift(1)\n",
    "\n",
    "    sign_rot = np.sign(delta_mid).fillna(0.0)\n",
    "\n",
    "    rotation_index = sign_rot.rolling(win, min_periods=1).mean()\n",
    "    rotation_index = rotation_index.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return pd.Series(rotation_index.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "484e233192fd4f16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: range_tagging_bias_50\n",
    "FEATURE_CODE = \"range_tagging_bias_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Range Tagging Bias (50-bar window)\n",
    "\n",
    "    Logic:\n",
    "      - Compute 50-bar high, low and range:\n",
    "          high50, low50, range50\n",
    "      - Define a tagging threshold:\n",
    "          thresh = 0.10 * range50\n",
    "      - For each bar:\n",
    "          high_tag = 1 if (high50 - close) <= thresh\n",
    "          low_tag  = 1 if (close - low50)  <= thresh\n",
    "        (If both are true, they both count; rare except very narrow ranges.)\n",
    "      - Over last 50 bars:\n",
    "          high_count = sum(high_tag)\n",
    "          low_count  = sum(low_tag)\n",
    "          bias = (high_count - low_count) / 50\n",
    "\n",
    "      Interpretation:\n",
    "        +1 → mostly tagging upper part of range\n",
    "        -1 → mostly tagging lower part\n",
    "         0 → symmetric.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    win = 50\n",
    "\n",
    "    high50 = high.rolling(win).max()\n",
    "    low50  = low .rolling(win).min()\n",
    "    range50 = (high50 - low50).replace(0.0, np.nan)\n",
    "\n",
    "    thresh = 0.10 * range50\n",
    "\n",
    "    high_tag = ((high50 - close) <= thresh).astype(float)\n",
    "    low_tag  = ((close - low50) <= thresh).astype(float)\n",
    "\n",
    "    high_count = high_tag.rolling(win, min_periods=1).sum()\n",
    "    low_count  = low_tag .rolling(win, min_periods=1).sum()\n",
    "\n",
    "    bias = (high_count - low_count) / float(win)\n",
    "    bias = bias.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return pd.Series(bias.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "7b0b4da4dc76743d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: reg_shift_flag_50\n",
    "FEATURE_CODE = \"reg_shift_flag_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Regime Shift Flag (50-bar comparison)\n",
    "\n",
    "    Logic:\n",
    "      - Compute 50-bar range:    range50 = max(high,50) - min(low,50)\n",
    "      - Trend component:         trend50 = (close - close.shift(50)) / (range50 + eps)\n",
    "      - Volatility component:    vol50   = mean(true_range,50) / (mean(close,50) + eps)\n",
    "      - Regime score:            regime  = trend50 * vol50\n",
    "\n",
    "      For each bar, compare regime_score with regime_score 50 bars ago:\n",
    "        - Both magnitudes must be larger than a small threshold.\n",
    "        - Signs must be different (trend direction flip).\n",
    "        - Absolute difference must exceed another threshold.\n",
    "\n",
    "      If all conditions are met → flag = 1, else 0.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low  = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    win = 50\n",
    "    eps = 1e-9\n",
    "\n",
    "    # 50-bar range\n",
    "    high50 = high.rolling(win).max()\n",
    "    low50  = low .rolling(win).min()\n",
    "    range50 = (high50 - low50).replace(0.0, np.nan)\n",
    "\n",
    "    # True range approximation\n",
    "    tr = (high - low).abs()\n",
    "    tr_mean50 = tr.rolling(win).mean()\n",
    "\n",
    "    close_mean50 = close.rolling(win).mean()\n",
    "\n",
    "    trend50 = (close - close.shift(win)) / (range50 + eps)\n",
    "    vol50   = tr_mean50 / (close_mean50.abs() + eps)\n",
    "\n",
    "    regime = trend50 * vol50\n",
    "\n",
    "    # Compare with regime 50 bars ago\n",
    "    regime_prev = regime.shift(win)\n",
    "\n",
    "    # Conditions for a regime shift\n",
    "    mag_thresh = 0.02\n",
    "    diff_thresh = 0.05\n",
    "\n",
    "    cond_mag = (regime.abs() > mag_thresh) & (regime_prev.abs() > mag_thresh)\n",
    "    cond_sign = (np.sign(regime) != np.sign(regime_prev))\n",
    "    cond_jump = (regime - regime_prev).abs() > diff_thresh\n",
    "\n",
    "    flag = (cond_mag & cond_sign & cond_jump).astype(int).fillna(0)\n",
    "\n",
    "    return pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "4ab4cdfbc24f479f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: reg_trending_flag_30\n",
    "FEATURE_CODE = \"reg_trending_flag_30\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Regime Trending Flag (30-bar window)\n",
    "\n",
    "    Logic:\n",
    "      Flags whether the market is in a trending regime over the last ~30 bars.\n",
    "\n",
    "      Steps:\n",
    "        - Compute an ATR-like volatility using a 14-bar mean of true range:\n",
    "              tr  = |high - low|\n",
    "              atr14 = mean(tr, 14)\n",
    "        - Compute a 30-bar net slope of close:\n",
    "              slope30 = (close - close.shift(30)) / 30\n",
    "        - Normalize slope by volatility:\n",
    "              norm_slope = |slope30| / (atr14 + eps)\n",
    "        - Flag as trending if norm_slope > threshold.\n",
    "\n",
    "      Output:\n",
    "        Integer flag in {0, 1}.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low  = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    eps = 1e-9\n",
    "\n",
    "    # True range and ATR-like volatility\n",
    "    tr = (high - low).abs()\n",
    "    atr14 = tr.rolling(14).mean()\n",
    "\n",
    "    # 30-bar slope of close\n",
    "    slope30 = (close - close.shift(30)) / 30.0\n",
    "\n",
    "    norm_slope = slope30.abs() / (atr14 + eps)\n",
    "\n",
    "    # Threshold can be tuned based on asset / timeframe\n",
    "    threshold = 0.5\n",
    "    flag = (norm_slope > threshold).astype(int).fillna(0)\n",
    "\n",
    "    return pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "4dfcd9590d38bbef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: session_displacement_ratio_1d\n",
    "FEATURE_CODE = \"session_displacement_ratio_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Session Displacement Ratio (1-day)\n",
    "\n",
    "    Requirements:\n",
    "      - Index must be a DatetimeIndex.\n",
    "      - Data is assumed intraday, with multiple bars per calendar day.\n",
    "\n",
    "    Logic:\n",
    "      For each calendar day:\n",
    "        - open_d  = first close of the day (or open if you replace it)\n",
    "        - close_d = last close of the day\n",
    "        - high_d  = max high of the day\n",
    "        - low_d   = min low of the day\n",
    "        - displacement = close_d - open_d\n",
    "        - range       = high_d - low_d\n",
    "\n",
    "      Session-level metric:\n",
    "        ratio_d = displacement / (range + eps)\n",
    "\n",
    "      That daily ratio is then mapped back to all bars of the same day.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    if not isinstance(g.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"session_displacement_ratio_1d requires a DatetimeIndex.\")\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low  = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    dates = g.index.normalize()\n",
    "\n",
    "    temp = pd.DataFrame({\n",
    "        \"high\": high,\n",
    "        \"low\": low,\n",
    "        \"close\": close,\n",
    "        \"date\": dates,\n",
    "    })\n",
    "\n",
    "    grouped = temp.groupby(\"date\", sort=False)\n",
    "\n",
    "    high_d  = grouped[\"high\"].max()\n",
    "    low_d   = grouped[\"low\"].min()\n",
    "    close_d = grouped[\"close\"].last()\n",
    "    open_d  = grouped[\"close\"].first()  # if you have 'open', swap to grouped[\"open\"].first()\n",
    "\n",
    "    displacement = close_d - open_d\n",
    "    session_range = (high_d - low_d).replace(0.0, np.nan)\n",
    "\n",
    "    ratio_d = displacement / (session_range + 1e-9)\n",
    "    ratio_d = ratio_d.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    # Broadcast daily values to intraday index\n",
    "    session_ratio = pd.Series(ratio_d.reindex(dates).values, index=g.index)\n",
    "\n",
    "    return session_ratio.rename(FEATURE_CODE)\n"
   ],
   "id": "59bfeaf9421b74f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: session_high_low_shift_dir_3d\n",
    "FEATURE_CODE = \"session_high_low_shift_dir_3d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Session High–Low Shift Direction (3-day window)\n",
    "\n",
    "    Requirements:\n",
    "      - Index must be a DatetimeIndex.\n",
    "      - Data is assumed intraday with multiple bars per calendar day.\n",
    "\n",
    "    Logic:\n",
    "      For each calendar day:\n",
    "        - high_d = max(high) of the day\n",
    "        - low_d  = min(low) of the day\n",
    "\n",
    "      Then:\n",
    "        - 1-day shift score:\n",
    "            shift_score_d = ((high_d - high_d.shift(1)) +\n",
    "                             (low_d  - low_d.shift(1))) / 2\n",
    "        - 3-day smoothed shift:\n",
    "            shift_mean3 = rolling_mean(shift_score_d, 3)\n",
    "        - Direction:\n",
    "            dir_d = sign(shift_mean3)   in {-1, 0, +1}\n",
    "\n",
    "      That daily direction is broadcast to all intraday bars of the same day.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    if not isinstance(g.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"session_high_low_shift_dir_3d requires a DatetimeIndex.\")\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low  = g[\"low\"].astype(float)\n",
    "\n",
    "    dates = g.index.normalize()\n",
    "\n",
    "    temp = pd.DataFrame({\"high\": high, \"low\": low, \"date\": dates})\n",
    "\n",
    "    grouped = temp.groupby(\"date\", sort=False)\n",
    "    high_d = grouped[\"high\"].max()\n",
    "    low_d  = grouped[\"low\"].min()\n",
    "\n",
    "    # 1-day shift in highs and lows\n",
    "    shift_score = ((high_d - high_d.shift(1)) +\n",
    "                   (low_d  - low_d.shift(1))) / 2.0\n",
    "\n",
    "    # 3-day smoothed direction\n",
    "    shift_mean3 = shift_score.rolling(3, min_periods=1).mean()\n",
    "    dir_d = np.sign(shift_mean3).fillna(0.0)\n",
    "\n",
    "    dir_series = pd.Series(dir_d.reindex(dates).values, index=g.index)\n",
    "\n",
    "    return dir_series.rename(FEATURE_CODE)\n"
   ],
   "id": "264ada466a95246d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: session_initial_balance_breakout_flag_1d\n",
    "FEATURE_CODE = \"session_initial_balance_breakout_flag_1d\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Session Initial Balance Breakout Flag (1-day)\n",
    "\n",
    "    Requirements:\n",
    "      - Index must be a DatetimeIndex.\n",
    "      - Data is assumed intraday with multiple bars per calendar day.\n",
    "\n",
    "    Logic (bar-count based Initial Balance):\n",
    "      For each calendar day:\n",
    "        - Let n = number of bars in that day.\n",
    "        - Initial Balance (IB) = first max(int(0.25 * n), 1) bars.\n",
    "        - IB_high = max(high over IB bars)\n",
    "        - IB_low  = min(low  over IB bars)\n",
    "\n",
    "      For each bar in that day:\n",
    "        - If bar is after the IB segment AND\n",
    "             (high > IB_high OR low < IB_low)\n",
    "          then breakout_flag = 1\n",
    "          else 0.\n",
    "\n",
    "      Output:\n",
    "        Per-bar integer flag in {0, 1}.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    if not isinstance(g.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"session_initial_balance_breakout_flag_1d requires a DatetimeIndex.\")\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low  = g[\"low\"].astype(float)\n",
    "\n",
    "    dates = g.index.normalize()\n",
    "\n",
    "    temp = pd.DataFrame({\"high\": high, \"low\": low, \"date\": dates})\n",
    "    grouped = temp.groupby(\"date\", sort=False)\n",
    "\n",
    "    breakout_flag = pd.Series(0, index=g.index, dtype=int)\n",
    "\n",
    "    for date_val, grp in grouped:\n",
    "        n = len(grp)\n",
    "        if n <= 1:\n",
    "            continue\n",
    "\n",
    "        # IB defined as first 25% of bars in that day\n",
    "        ib_count = max(int(round(0.25 * n)), 1)\n",
    "\n",
    "        ib_slice = grp.iloc[:ib_count]\n",
    "        ib_high = ib_slice[\"high\"].max()\n",
    "        ib_low  = ib_slice[\"low\"].min()\n",
    "\n",
    "        # Bars after IB\n",
    "        after_ib = grp.iloc[ib_count:]\n",
    "\n",
    "        cond_break = (after_ib[\"high\"] > ib_high) | (after_ib[\"low\"] < ib_low)\n",
    "        breakout_flag.loc[after_ib.index] = cond_break.astype(int)\n",
    "\n",
    "    return breakout_flag.rename(FEATURE_CODE)\n"
   ],
   "id": "c718e19eb13d57fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: smc_liquidity_void_depth_50\n",
    "FEATURE_CODE = \"smc_liquidity_void_depth_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    SMC Liquidity Void Depth (50-bar window)\n",
    "\n",
    "    Logic:\n",
    "      A simple quantitative proxy for liquidity void / imbalance depth.\n",
    "\n",
    "      For each bar:\n",
    "        - gap_up   = low > high.shift(1)\n",
    "                     gap_up_depth = low - high.shift(1)\n",
    "        - gap_down = high < low.shift(1)\n",
    "                     gap_down_depth = low.shift(1) - high\n",
    "\n",
    "        - void_depth_bar = max(gap_up_depth, gap_down_depth, 0)\n",
    "\n",
    "      Then over a 50-bar rolling window:\n",
    "        - max_void_50 = rolling max(void_depth_bar, 50)\n",
    "        - range50     = rolling range of high/low over 50 bars\n",
    "        - feature     = max_void_50 / (range50 + eps)\n",
    "\n",
    "      Output:\n",
    "        Float in [0, 1+] indicating relative depth of the largest void\n",
    "        within the last 50 bars.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low  = g[\"low\"].astype(float)\n",
    "\n",
    "    prev_high = high.shift(1)\n",
    "    prev_low  = low.shift(1)\n",
    "\n",
    "    # Gap up void\n",
    "    gap_up = (low > prev_high)\n",
    "    gap_up_depth = (low - prev_high).where(gap_up, 0.0)\n",
    "\n",
    "    # Gap down void\n",
    "    gap_down = (high < prev_low)\n",
    "    gap_down_depth = (prev_low - high).where(gap_down, 0.0)\n",
    "\n",
    "    void_depth_bar = np.maximum(gap_up_depth, gap_down_depth).fillna(0.0)\n",
    "\n",
    "    win = 50\n",
    "    max_void_50 = void_depth_bar.rolling(win).max()\n",
    "\n",
    "    high50 = high.rolling(win).max()\n",
    "    low50  = low .rolling(win).min()\n",
    "    range50 = (high50 - low50).replace(0.0, np.nan)\n",
    "\n",
    "    eps = 1e-9\n",
    "    depth_norm = max_void_50 / (range50 + eps)\n",
    "    depth_norm = depth_norm.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return pd.Series(depth_norm.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "e73d7c18ebb40e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: structural_hh_hl_trend_score_50\n",
    "FEATURE_CODE = \"structural_hh_hl_trend_score_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Structural HH/HL Trend Score (50-bar window)\n",
    "\n",
    "    Logic:\n",
    "      A simple bar-level structural proxy:\n",
    "\n",
    "      For each bar:\n",
    "        - up_struct   = 1 if high > prev_high and low > prev_low      (HH + HL)\n",
    "        - down_struct = -1 if high < prev_high and low < prev_low     (LL + LH)\n",
    "        - else 0\n",
    "\n",
    "      Then:\n",
    "        trend_score_50 = rolling mean of this structural sign over 50 bars.\n",
    "\n",
    "      Output:\n",
    "        Float in [-1, 1]:\n",
    "          +1 ~ strongly HH/HL\n",
    "          -1 ~ strongly LL/LH\n",
    "           0 ~ mixed/choppy.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low  = g[\"low\"].astype(float)\n",
    "\n",
    "    prev_high = high.shift(1)\n",
    "    prev_low  = low.shift(1)\n",
    "\n",
    "    up_struct   = ((high > prev_high) & (low > prev_low)).astype(int)\n",
    "    down_struct = ((high < prev_high) & (low < prev_low)).astype(int) * -1\n",
    "\n",
    "    struct_sign = up_struct + down_struct\n",
    "    struct_sign = struct_sign.astype(float).fillna(0.0)\n",
    "\n",
    "    win = 50\n",
    "    trend_score = struct_sign.rolling(win, min_periods=1).mean()\n",
    "    trend_score = trend_score.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return pd.Series(trend_score.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "ee2865ccfabb5ec3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: structure_shift_score_30\n",
    "FEATURE_CODE = \"structure_shift_score_30\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Structure Shift Score (30-bar comparison)\n",
    "\n",
    "    Logic:\n",
    "      1) Build a simple structural sign per bar:\n",
    "           +1 if high > prev_high and low > prev_low    (HH + HL)\n",
    "           -1 if high < prev_high and low < prev_low    (LL + LH)\n",
    "            0 otherwise.\n",
    "\n",
    "      2) Compute a 30-bar rolling mean of this structural sign:\n",
    "           bias_30\n",
    "\n",
    "      3) Compare the current bias_30 with bias_30 from 30 bars ago:\n",
    "           shift_score = bias_30 - bias_30.shift(30)\n",
    "\n",
    "      Interpretation:\n",
    "        - Large positive values → structural regime has shifted toward bullish.\n",
    "        - Large negative values → structural regime has shifted toward bearish.\n",
    "        - Values near zero → little net structural change over that horizon.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low  = g[\"low\"].astype(float)\n",
    "\n",
    "    prev_high = high.shift(1)\n",
    "    prev_low  = low.shift(1)\n",
    "\n",
    "    up_struct   = ((high > prev_high) & (low > prev_low)).astype(int)\n",
    "    down_struct = ((high < prev_high) & (low < prev_low)).astype(int) * -1\n",
    "\n",
    "    struct_sign = (up_struct + down_struct).astype(float).fillna(0.0)\n",
    "\n",
    "    win = 30\n",
    "\n",
    "    bias_30 = struct_sign.rolling(win, min_periods=1).mean()\n",
    "    shift_score = bias_30 - bias_30.shift(win)\n",
    "\n",
    "    shift_score = shift_score.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return pd.Series(shift_score.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "f02e86729568462f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: sweep_and_break_flag_20\n",
    "FEATURE_CODE = \"sweep_and_break_flag_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Sweep-and-Break Flag (20-bar lookback)\n",
    "\n",
    "    Logic (single-bar proxy):\n",
    "\n",
    "      1) Compute prior 20-bar extremes (excluding current bar):\n",
    "           prior_high_20 = rolling_max(high, 20).shift(1)\n",
    "           prior_low_20  = rolling_min(low,  20).shift(1)\n",
    "\n",
    "      2) Define:\n",
    "           up_sweep   = high > prior_high_20\n",
    "           down_sweep = low  < prior_low_20\n",
    "\n",
    "      3) Define \"break\" in the opposite direction using bar close vs open:\n",
    "           break_down_after_up = (up_sweep   & (close < open))\n",
    "           break_up_after_down = (down_sweep & (close > open))\n",
    "\n",
    "      4) Flag:\n",
    "           flag = 1 if either break_down_after_up or break_up_after_down, else 0.\n",
    "\n",
    "      This is a compact, event-style SMC proxy:\n",
    "        - It first takes liquidity beyond a prior local extreme (sweep),\n",
    "        - Then closes with momentum in the opposite direction (break).\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high  = g[\"high\"].astype(float)\n",
    "    low   = g[\"low\"].astype(float)\n",
    "    open_ = g[\"open\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    lookback = 20\n",
    "\n",
    "    prior_high_20 = high.rolling(lookback).max().shift(1)\n",
    "    prior_low_20  = low .rolling(lookback).min().shift(1)\n",
    "\n",
    "    up_sweep   = (high > prior_high_20)\n",
    "    down_sweep = (low  < prior_low_20)\n",
    "\n",
    "    break_down_after_up = up_sweep & (close < open_)\n",
    "    break_up_after_down = down_sweep & (close > open_)\n",
    "\n",
    "    flag = (break_down_after_up | break_up_after_down).astype(int).fillna(0)\n",
    "\n",
    "    return pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "45d1f2635c3bbfa3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: session_killzone_activity_index\n",
    "FEATURE_CODE = \"session_killzone_activity_index\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Session Killzone Activity Index (1-day)\n",
    "\n",
    "    Clean, vectorized, and warning-free version.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    if not isinstance(g.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"session_killzone_activity_index requires a DatetimeIndex.\")\n",
    "\n",
    "    high = g[\"high\"].astype(float)\n",
    "    low  = g[\"low\"].astype(float)\n",
    "\n",
    "    tr = (high - low).abs()\n",
    "\n",
    "    dates = g.index.normalize()\n",
    "    hours = g.index.hour\n",
    "\n",
    "    killzone_mask = (\n",
    "        ((hours >= 7) & (hours < 10)) |   # London\n",
    "        ((hours >= 13) & (hours < 16))    # New York\n",
    "    )\n",
    "\n",
    "    temp = pd.DataFrame({\n",
    "        \"tr\": tr,\n",
    "        \"date\": dates,\n",
    "        \"killzone\": killzone_mask.astype(bool),\n",
    "    })\n",
    "\n",
    "    grouped = temp.groupby(\"date\", sort=False)\n",
    "\n",
    "    # Daily TR sum (vectorized)\n",
    "    daily_tr_sum = grouped[\"tr\"].sum()\n",
    "\n",
    "    # Killzone TR sum (vectorized & no warning)\n",
    "    kill_tr_sum = temp.loc[temp[\"killzone\"], :].groupby(\"date\")[\"tr\"].sum()\n",
    "    kill_tr_sum = kill_tr_sum.reindex(daily_tr_sum.index).fillna(0.0)\n",
    "\n",
    "    eps = 1e-9\n",
    "    activity_d = kill_tr_sum / (daily_tr_sum + eps)\n",
    "    activity_d = activity_d.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    # Broadcast to full index\n",
    "    activity_series = pd.Series(activity_d.reindex(dates).values, index=g.index)\n",
    "\n",
    "    return activity_series.rename(FEATURE_CODE)\n"
   ],
   "id": "144778f83f68b081"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: swing_failure_pattern_flag_20\n",
    "FEATURE_CODE = \"swing_failure_pattern_flag_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Swing Failure Pattern Flag (20-bar lookback)\n",
    "\n",
    "    Logic:\n",
    "      Uses prior 20-bar extremes as liquidity reference.\n",
    "\n",
    "      - prior_high_20 = rolling max(high, 20).shift(1)\n",
    "      - prior_low_20  = rolling min(low,  20).shift(1)\n",
    "\n",
    "      Bearish SFP (of a high):\n",
    "        - high > prior_high_20       (sweep the prior high)\n",
    "        - close < prior_high_20      (close back below the level)\n",
    "        - optional: close < open     (bearish close)\n",
    "\n",
    "      Bullish SFP (of a low):\n",
    "        - low < prior_low_20         (sweep the prior low)\n",
    "        - close > prior_low_20       (close back above the level)\n",
    "        - optional: close > open     (bullish close)\n",
    "\n",
    "      If either bullish or bearish SFP occurs → flag = 1, else 0.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high  = g[\"high\"].astype(float)\n",
    "    low   = g[\"low\"].astype(float)\n",
    "    open_ = g[\"open\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    lookback = 20\n",
    "\n",
    "    prior_high_20 = high.rolling(lookback).max().shift(1)\n",
    "    prior_low_20  = low .rolling(lookback).min().shift(1)\n",
    "\n",
    "    # Bearish SFP: sweep above prior high, close back below it, bearish candle\n",
    "    bearish_sfp = (\n",
    "        (high > prior_high_20) &\n",
    "        (close < prior_high_20) &\n",
    "        (close < open_)\n",
    "    )\n",
    "\n",
    "    # Bullish SFP: sweep below prior low, close back above it, bullish candle\n",
    "    bullish_sfp = (\n",
    "        (low < prior_low_20) &\n",
    "        (close > prior_low_20) &\n",
    "        (close > open_)\n",
    "    )\n",
    "\n",
    "    flag = (bearish_sfp | bullish_sfp).astype(int).fillna(0)\n",
    "\n",
    "    return pd.Series(flag.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "db14b6eeaf490353"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: swing_leg_efficiency_ratio_30\n",
    "FEATURE_CODE = \"swing_leg_efficiency_ratio_30\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Swing Leg Efficiency Ratio (30-bar window)\n",
    "\n",
    "    Logic:\n",
    "      For each bar t:\n",
    "\n",
    "        net_move   = |close_t - close_{t-30}|\n",
    "        path_sum   = sum_{i=t-29..t} |close_i - close_{i-1}|\n",
    "        efficiency = net_move / (path_sum + eps)\n",
    "\n",
    "      Interpretation:\n",
    "        - Values near 1 → very directional leg (trend-like).\n",
    "        - Values near 0 → highly choppy, mean-reverting movement.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    win = 30\n",
    "    eps = 1e-9\n",
    "\n",
    "    # Net move over 30 bars\n",
    "    net_move = (close - close.shift(win)).abs()\n",
    "\n",
    "    # Step-wise absolute changes\n",
    "    step_change = close.diff().abs()\n",
    "\n",
    "    # Rolling sum of absolute changes over 30 bars\n",
    "    path_sum = step_change.rolling(win, min_periods=1).sum()\n",
    "\n",
    "    efficiency = net_move / (path_sum + eps)\n",
    "    efficiency = efficiency.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return pd.Series(efficiency.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "1bf0f2a29ecd194d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: fvg_fill_ratio_30\n",
    "FEATURE_CODE = \"fvg_fill_ratio_30\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    FVG Fill Ratio (30-bar lifetime, single active gap)\n",
    "\n",
    "    Logic:\n",
    "      - Detect 3-bar Fair Value Gaps (FVG) using:\n",
    "          Bullish FVG at bar n:\n",
    "            low_n > high_{n-2}\n",
    "            gap range: [gap_low, gap_high] = [high_{n-2}, low_n]\n",
    "\n",
    "          Bearish FVG at bar n:\n",
    "            high_n < low_{n-2}\n",
    "            gap range: [gap_low, gap_high] = [high_n, low_{n-2}]\n",
    "\n",
    "      - Track at most one active FVG at a time:\n",
    "          - gap_low, gap_high, gap_start_idx\n",
    "          - covered_low, covered_high = union of portions of gap that have traded\n",
    "\n",
    "      - For each bar t:\n",
    "          1) If an active gap exists:\n",
    "               - Compute overlap between [low_t, high_t] and [gap_low, gap_high].\n",
    "               - Expand (covered_low, covered_high) by this overlap.\n",
    "               - Compute:\n",
    "                   gap_size      = gap_high - gap_low\n",
    "                   covered_size  = max(0, covered_high - covered_low)\n",
    "                   fill_ratio_t  = covered_size / gap_size\n",
    "               - If fully filled OR t - gap_start_idx >= 30 → expire gap.\n",
    "          2) If no active gap exists, check if a new FVG starts at t (using bars t, t-1, t-2).\n",
    "\n",
    "      Output:\n",
    "        fill_ratio_t in [0, 1] for the currently tracked FVG up to time t.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high = g[\"high\"].astype(float).values\n",
    "    low  = g[\"low\"].astype(float).values\n",
    "\n",
    "    n = len(g)\n",
    "\n",
    "    fill_ratio = np.zeros(n, dtype=float)\n",
    "\n",
    "    current_gap_low = np.nan\n",
    "    current_gap_high = np.nan\n",
    "    covered_low = np.nan\n",
    "    covered_high = np.nan\n",
    "    gap_start_idx = None\n",
    "    max_lifetime = 30\n",
    "\n",
    "    for i in range(n):\n",
    "        h = high[i]\n",
    "        l = low[i]\n",
    "\n",
    "        # 1) If there is an active gap, update fill\n",
    "        if not np.isnan(current_gap_low):\n",
    "            # Overlap between current candle and gap\n",
    "            overlap_low = max(l, current_gap_low)\n",
    "            overlap_high = min(h, current_gap_high)\n",
    "\n",
    "            if overlap_high > overlap_low:\n",
    "                if np.isnan(covered_low):\n",
    "                    covered_low = overlap_low\n",
    "                    covered_high = overlap_high\n",
    "                else:\n",
    "                    covered_low = min(covered_low, overlap_low)\n",
    "                    covered_high = max(covered_high, overlap_high)\n",
    "\n",
    "            gap_size = current_gap_high - current_gap_low\n",
    "            if gap_size > 0:\n",
    "                if np.isnan(covered_low):\n",
    "                    covered_size = 0.0\n",
    "                else:\n",
    "                    covered_size = max(0.0, covered_high - covered_low)\n",
    "                fill_ratio[i] = covered_size / gap_size\n",
    "            else:\n",
    "                fill_ratio[i] = 0.0\n",
    "\n",
    "            # Expire if fully filled or too old\n",
    "            if gap_start_idx is not None:\n",
    "                if (gap_size <= 0) or (covered_size >= gap_size) or (i - gap_start_idx >= max_lifetime):\n",
    "                    current_gap_low = np.nan\n",
    "                    current_gap_high = np.nan\n",
    "                    covered_low = np.nan\n",
    "                    covered_high = np.nan\n",
    "                    gap_start_idx = None\n",
    "\n",
    "        # 2) If no active gap, check for a new FVG at this bar\n",
    "        if np.isnan(current_gap_low) and i >= 2:\n",
    "            h_2 = high[i - 2]\n",
    "            l_2 = low[i - 2]\n",
    "\n",
    "            # Bullish FVG (gap above bar n-2)\n",
    "            if l > h_2:\n",
    "                current_gap_low = h_2\n",
    "                current_gap_high = l\n",
    "                gap_start_idx = i\n",
    "                covered_low = np.nan\n",
    "                covered_high = np.nan\n",
    "\n",
    "            # Bearish FVG (gap below bar n-2)\n",
    "            elif h < l_2:\n",
    "                current_gap_low = h\n",
    "                current_gap_high = l_2\n",
    "                gap_start_idx = i\n",
    "                covered_low = np.nan\n",
    "                covered_high = np.nan\n",
    "\n",
    "        # If no gap, fill_ratio[i] stays as previous (default 0.0)\n",
    "\n",
    "    s = pd.Series(fill_ratio, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "f8fd08a35df4c4fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: liquidity_sweep_wick_ratio_20\n",
    "FEATURE_CODE = \"liquidity_sweep_wick_ratio_20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Liquidity Sweep Wick Ratio (20-bar lookback)\n",
    "\n",
    "    Logic:\n",
    "      Measures what fraction of the wick that sweeps liquidity lies\n",
    "      outside the prior 20-bar high/low.\n",
    "\n",
    "      Steps:\n",
    "        - prior_high_20 = rolling max(high, 20).shift(1)\n",
    "        - prior_low_20  = rolling min(low,  20).shift(1)\n",
    "\n",
    "        For each bar:\n",
    "          up_sweep   = high > prior_high_20\n",
    "          down_sweep = low  < prior_low_20\n",
    "\n",
    "          upper_body = max(open, close)\n",
    "          lower_body = min(open, close)\n",
    "\n",
    "          wick_above = max(0, high - upper_body)\n",
    "          wick_below = max(0, lower_body - low)\n",
    "\n",
    "          outside_up   = max(0, high - prior_high_20)\n",
    "          outside_down = max(0, prior_low_20 - low)\n",
    "\n",
    "          ratio_up   = outside_up   / wick_above   if wick_above   > 0\n",
    "          ratio_down = outside_down / wick_below   if wick_below   > 0\n",
    "\n",
    "      Feature:\n",
    "        liquidity_sweep_wick_ratio_20 = clip(ratio_up + ratio_down, 0, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high  = g[\"high\"].astype(float)\n",
    "    low   = g[\"low\"].astype(float)\n",
    "    open_ = g[\"open\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    lookback = 20\n",
    "\n",
    "    prior_high_20 = high.rolling(lookback).max().shift(1)\n",
    "    prior_low_20  = low .rolling(lookback).min().shift(1)\n",
    "\n",
    "    upper_body = np.maximum(open_, close)\n",
    "    lower_body = np.minimum(open_, close)\n",
    "\n",
    "    wick_above = (high - upper_body).clip(lower=0.0)\n",
    "    wick_below = (lower_body - low).clip(lower=0.0)\n",
    "\n",
    "    up_sweep   = (high > prior_high_20)\n",
    "    down_sweep = (low  < prior_low_20)\n",
    "\n",
    "    outside_up   = (high - prior_high_20).where(up_sweep, 0.0).clip(lower=0.0)\n",
    "    outside_down = (prior_low_20 - low).where(down_sweep, 0.0).clip(lower=0.0)\n",
    "\n",
    "    ratio_up = np.where(\n",
    "        wick_above > 0,\n",
    "        outside_up / wick_above,\n",
    "        0.0,\n",
    "    )\n",
    "\n",
    "    ratio_down = np.where(\n",
    "        wick_below > 0,\n",
    "        outside_down / wick_below,\n",
    "        0.0,\n",
    "    )\n",
    "\n",
    "    ratio = ratio_up + ratio_down\n",
    "    ratio = np.clip(ratio, 0.0, 1.0)\n",
    "\n",
    "    s = pd.Series(ratio, index=g.index, name=FEATURE_CODE)\n",
    "    return s\n"
   ],
   "id": "f9be940a81d279cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: market_structure_break_count_50\n",
    "FEATURE_CODE = \"market_structure_break_count_50\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Market Structure Break Count (50-bar window)\n",
    "\n",
    "    Logic:\n",
    "      A simple, direction-agnostic count of structure breaks.\n",
    "\n",
    "      1) Define prior 20-bar extremes (excluding current bar):\n",
    "           prior_high_20 = rolling_max(high, 20).shift(1)\n",
    "           prior_low_20  = rolling_min(low,  20).shift(1)\n",
    "\n",
    "      2) Structure breaks:\n",
    "           bull_break = close > prior_high_20\n",
    "           bear_break = close < prior_low_20\n",
    "\n",
    "      3) For each bar:\n",
    "           break_flag = 1 if (bull_break or bear_break) else 0\n",
    "\n",
    "      4) Feature:\n",
    "           market_structure_break_count_50 =\n",
    "               rolling_sum(break_flag over last 50 bars)\n",
    "\n",
    "      Output:\n",
    "        Non-negative float / int count.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high  = g[\"high\"].astype(float)\n",
    "    low   = g[\"low\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    lookback_ref = 20\n",
    "    lookback_count = 50\n",
    "\n",
    "    prior_high_20 = high.rolling(lookback_ref).max().shift(1)\n",
    "    prior_low_20  = low .rolling(lookback_ref).min().shift(1)\n",
    "\n",
    "    bull_break = (close > prior_high_20)\n",
    "    bear_break = (close < prior_low_20)\n",
    "\n",
    "    break_flag = (bull_break | bear_break).astype(float).fillna(0.0)\n",
    "\n",
    "    break_count_50 = break_flag.rolling(lookback_count, min_periods=1).sum()\n",
    "\n",
    "    return pd.Series(break_count_50.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "9f8b89e3fc18dd08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: time_dow_sin\n",
    "FEATURE_CODE = \"time_dow_sin\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Time-of-Week Sine Encoding (Day of Week)\n",
    "\n",
    "    Requirements:\n",
    "      - Index must be a DatetimeIndex.\n",
    "\n",
    "    Logic:\n",
    "      dow  = day_of_week in {0..6}\n",
    "      feat = sin(2π * dow / 7)\n",
    "\n",
    "      This gives a smooth cyclical representation of day-of-week\n",
    "      (useful for models that like continuous features).\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "\n",
    "    if not isinstance(g.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"time_dow_sin requires a DatetimeIndex.\")\n",
    "\n",
    "    dow = g.index.dayofweek.astype(float)  # Monday=0, Sunday=6\n",
    "\n",
    "    values = np.sin(2.0 * np.pi * dow / 7.0)\n",
    "\n",
    "    return pd.Series(values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "d044f528a5a608bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: time_hour_sin\n",
    "FEATURE_CODE = \"time_hour_sin\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Time-of-Day Sine Encoding (Hour of Day)\n",
    "\n",
    "    Requirements:\n",
    "      - Index must be a DatetimeIndex.\n",
    "      - Data is intraday (or at least has hour information).\n",
    "\n",
    "    Logic:\n",
    "      hour = index.hour in {0..23}\n",
    "      feat = sin(2π * hour / 24)\n",
    "\n",
    "      This encodes time-of-day as a smooth cyclic feature.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "\n",
    "    if not isinstance(g.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"time_hour_sin requires a DatetimeIndex.\")\n",
    "\n",
    "    hour = g.index.hour.astype(float)\n",
    "    values = np.sin(2.0 * np.pi * hour / 24.0)\n",
    "\n",
    "    return pd.Series(values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "cbf507ac28c6fced"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: time_to_close_ratio\n",
    "FEATURE_CODE = \"time_to_close_ratio\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Time-to-Close Ratio (per calendar day, bar-count based)\n",
    "\n",
    "    Requirements:\n",
    "      - Index must be a DatetimeIndex.\n",
    "      - Data is intraday with multiple bars per calendar day.\n",
    "\n",
    "    Logic:\n",
    "      For each calendar day with n bars:\n",
    "\n",
    "        Bars are ordered: j = 0, 1, ..., n-1\n",
    "\n",
    "        time_to_close_ratio_j = (n - 1 - j) / max(1, n - 1)\n",
    "\n",
    "      Interpretation:\n",
    "        - First bar of the day  → ~1.0\n",
    "        - Last bar of the day   → 0.0\n",
    "        - Linearly decreasing in between.\n",
    "\n",
    "      This is a bar-count based approximation of \"how much of the session is left\".\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "\n",
    "    if not isinstance(g.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"time_to_close_ratio requires a DatetimeIndex.\")\n",
    "\n",
    "    dates = g.index.normalize()\n",
    "    temp = pd.DataFrame({\"date\": dates})\n",
    "    ratios = pd.Series(0.0, index=g.index, name=FEATURE_CODE)\n",
    "\n",
    "    # Group by calendar day\n",
    "    for date_val, grp_idx in temp.groupby(\"date\").groups.items():\n",
    "        idx = grp_idx  # index positions for this day\n",
    "        n = len(idx)\n",
    "        if n == 1:\n",
    "            # Only one bar: we consider it as \"at close\"\n",
    "            ratios.iloc[idx] = 0.0\n",
    "            continue\n",
    "\n",
    "        j = np.arange(n, dtype=float)\n",
    "        denom = max(1.0, float(n - 1))\n",
    "        day_ratios = (denom - j) / denom\n",
    "\n",
    "        ratios.iloc[idx] = day_ratios\n",
    "\n",
    "    return ratios\n"
   ],
   "id": "44ebe12f88a8235d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JUPYTER CELL — feature: wick_rejection_intensity_10\n",
    "FEATURE_CODE = \"wick_rejection_intensity_10\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_feature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Wick Rejection Intensity (10-bar z-score)\n",
    "\n",
    "    Logic:\n",
    "      Step 1: For each bar, compute wick size relative to its range.\n",
    "\n",
    "        upper_body = max(open, close)\n",
    "        lower_body = min(open, close)\n",
    "\n",
    "        upper_wick = max(0, high - upper_body)\n",
    "        lower_wick = max(0, lower_body - low)\n",
    "\n",
    "        wick_size  = max(upper_wick, lower_wick)\n",
    "        tr         = high - low\n",
    "\n",
    "        raw_intensity = wick_size / (tr + eps)\n",
    "\n",
    "      Step 2: Normalize vs recent history (10-bar window):\n",
    "\n",
    "        mean_10 = rolling_mean(raw_intensity, 10)\n",
    "        std_10  = rolling_std(raw_intensity, 10)\n",
    "\n",
    "        z_score = (raw_intensity - mean_10) / (std_10 + eps)\n",
    "\n",
    "      Output:\n",
    "        wick_rejection_intensity_10 = z_score\n",
    "        Positive values = unusually large wick relative to the last 10 bars.\n",
    "    \"\"\"\n",
    "\n",
    "    g = df.copy()\n",
    "    g.columns = [str(c).lower() for c in g.columns]\n",
    "\n",
    "    high  = g[\"high\"].astype(float)\n",
    "    low   = g[\"low\"].astype(float)\n",
    "    open_ = g[\"open\"].astype(float)\n",
    "    close = g[\"close\"].astype(float)\n",
    "\n",
    "    eps = 1e-9\n",
    "\n",
    "    upper_body = np.maximum(open_, close)\n",
    "    lower_body = np.minimum(open_, close)\n",
    "\n",
    "    upper_wick = (high - upper_body).clip(lower=0.0)\n",
    "    lower_wick = (lower_body - low).clip(lower=0.0)\n",
    "\n",
    "    wick_size = np.maximum(upper_wick, lower_wick)\n",
    "    tr = (high - low).abs()\n",
    "\n",
    "    raw_intensity = wick_size / (tr + eps)\n",
    "    raw_intensity = raw_intensity.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    win = 10\n",
    "    mean_10 = raw_intensity.rolling(win, min_periods=1).mean()\n",
    "    std_10  = raw_intensity.rolling(win, min_periods=1).std(ddof=0)\n",
    "\n",
    "    z_score = (raw_intensity - mean_10) / (std_10 + eps)\n",
    "    z_score = z_score.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return pd.Series(z_score.values, index=g.index, name=FEATURE_CODE)\n"
   ],
   "id": "9dac678d2e96dc07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "s = compute_feature(df)\n",
    "assert isinstance(s, pd.Series)\n",
    "assert s.name == FEATURE_CODE\n",
    "assert s.index.equals(df.index)\n",
    "assert len(s) == len(df)\n",
    "print(\"OK:\", FEATURE_CODE, len(s))"
   ],
   "id": "117bae559655a287"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ae0fceb2434e1aca"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
