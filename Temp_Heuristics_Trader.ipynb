{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+m3FarrHf1PEwNafVlPeC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NegativeGravity/Heuristic_Trader/blob/main/Temp_Heuristics_Trader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Tuple, Dict, Optional, Literal\n",
        "from numba import njit\n",
        "from google.colab import drive\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION & TYPES\n",
        "# ==========================================\n",
        "@dataclass(frozen=True)\n",
        "class Config:\n",
        "    \"\"\"Immutable configuration for the trading system.\"\"\"\n",
        "    # Risk Management\n",
        "    risk_per_trade: float = 0.01\n",
        "    reward_risk_ratio: float = 2.0\n",
        "    sl_min: float = 0.005\n",
        "    sl_max: float = 0.04\n",
        "    initial_capital: float = 1000.0\n",
        "    commission: float = 0.0006\n",
        "\n",
        "    # Genetic Algorithm\n",
        "    pop_size: int = 100\n",
        "    n_generations: int = 10000\n",
        "    mutation_rate: int = 0.15\n",
        "    max_conditions: int = 1\n",
        "    min_trades: int = 30\n",
        "\n",
        "    # WFA Settings\n",
        "    train_window: int = 15000  # ~52 days (5m candles)\n",
        "    test_window: int = 15000    # ~10 days\n",
        "\n",
        "@dataclass\n",
        "class Chromosome:\n",
        "    \"\"\"Represents a trading strategy candidate.\"\"\"\n",
        "    active_conds: np.ndarray\n",
        "    feature_idxs: np.ndarray\n",
        "    operators: np.ndarray\n",
        "    threshold_quantiles: np.ndarray\n",
        "    sl_gene: float\n",
        "\n",
        "@dataclass\n",
        "class StrategyResult:\n",
        "    \"\"\"Structured result of a strategy evaluation.\"\"\"\n",
        "    score: float\n",
        "    trades: int\n",
        "    win_rate: float\n",
        "    equity: float\n",
        "    rules: List[str]\n",
        "    sl_pct: float\n",
        "    tp_pct: float\n",
        "    side: int # 1 for Long, -1 for Short"
      ],
      "metadata": {
        "id": "a8UcS7YLBzhY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hnZqLWByy-Jr"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 2. NUMBA OPTIMIZED CORE (The Engine)\n",
        "# ==========================================\n",
        "@njit(fastmath=True)\n",
        "def calculate_signals_numba(n_rows, max_conds, active_conds, feature_idxs,\n",
        "                          operators, thresholds, feature_matrix):\n",
        "    \"\"\"\n",
        "    Generates signals based on conditions. Pure function.\n",
        "    \"\"\"\n",
        "    signal_mask = np.ones(n_rows, dtype=np.bool_)\n",
        "    active_count = 0\n",
        "\n",
        "    for i in range(max_conds):\n",
        "        if active_conds[i] == 1:\n",
        "            active_count += 1\n",
        "            col_data = feature_matrix[:, feature_idxs[i]]\n",
        "            thresh_val = thresholds[i]\n",
        "\n",
        "            # Operator 0: < (Less Than), Operator 1: > (Greater Than)\n",
        "            if operators[i] == 0:\n",
        "                for r in range(n_rows):\n",
        "                    if not (col_data[r] < thresh_val): signal_mask[r] = False\n",
        "            else:\n",
        "                for r in range(n_rows):\n",
        "                    if not (col_data[r] > thresh_val): signal_mask[r] = False\n",
        "\n",
        "    if active_count == 0:\n",
        "        return np.zeros(n_rows, dtype=np.bool_), 0\n",
        "    return signal_mask, active_count\n",
        "\n",
        "@njit(fastmath=True)\n",
        "def backtest_numba(close_prices: np.ndarray,\n",
        "                   signals: np.ndarray,\n",
        "                   side: int,  # 1 for Long, -1 for Short\n",
        "                   sl_pct: float,\n",
        "                   rr_ratio: float,\n",
        "                   init_capital: float,\n",
        "                   risk_per_trade: float,\n",
        "                   commission: float) -> Tuple[int, int, float]:\n",
        "    \"\"\"\n",
        "    Vectorized Backtest Engine supporting both Long and Short.\n",
        "    \"\"\"\n",
        "    n_rows = len(close_prices)\n",
        "    equity = init_capital\n",
        "    wins = 0\n",
        "    losses = 0\n",
        "    tp_pct = sl_pct * rr_ratio\n",
        "\n",
        "    i = 0\n",
        "    while i < n_rows - 1:\n",
        "        if signals[i]:\n",
        "            entry_price = close_prices[i]\n",
        "\n",
        "            # Position Sizing\n",
        "            risk_amt = equity * risk_per_trade\n",
        "            # Protect against zero division or negative prices\n",
        "            if entry_price <= 0:\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            position_size = risk_amt / (entry_price * sl_pct)\n",
        "\n",
        "            outcome = 0\n",
        "            for j in range(i + 1, n_rows):\n",
        "                current_price = close_prices[j]\n",
        "\n",
        "                # Calculate PnL % based on direction\n",
        "                # Long: (Cur - Ent) / Ent\n",
        "                # Short: (Ent - Cur) / Ent  => -1 * (Cur - Ent) / Ent\n",
        "                raw_return = (current_price - entry_price) / entry_price\n",
        "                pnl_pct = raw_return * side\n",
        "\n",
        "                # Check TP\n",
        "                if pnl_pct >= tp_pct:\n",
        "                    gross_profit = position_size * entry_price * tp_pct\n",
        "                    cost = (position_size * entry_price + position_size * current_price) * commission\n",
        "                    equity += (gross_profit - cost)\n",
        "                    wins += 1\n",
        "                    outcome = 1\n",
        "                    i = j\n",
        "                    break\n",
        "\n",
        "                # Check SL\n",
        "                elif pnl_pct <= -sl_pct:\n",
        "                    gross_loss = position_size * entry_price * sl_pct\n",
        "                    cost = (position_size * entry_price + position_size * current_price) * commission\n",
        "                    equity -= (gross_loss + cost)\n",
        "                    losses += 1\n",
        "                    outcome = -1\n",
        "                    i = j\n",
        "                    break\n",
        "\n",
        "            if outcome == 0:\n",
        "                i += 1 # Trade didn't close\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    return wins, losses, equity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3. GENETIC ALGORITHM LOGIC (SCORING 0-100)\n",
        "# ==========================================\n",
        "def create_random_chromosome(n_features: int, cfg: Config) -> Chromosome:\n",
        "    return Chromosome(\n",
        "        active_conds=np.random.randint(0, 2, size=cfg.max_conditions).astype(np.int64),\n",
        "        feature_idxs=np.random.randint(0, n_features, size=cfg.max_conditions).astype(np.int64),\n",
        "        operators=np.random.randint(0, 2, size=cfg.max_conditions).astype(np.int64),\n",
        "        threshold_quantiles=np.random.uniform(0.05, 0.95, size=cfg.max_conditions),\n",
        "        sl_gene=np.random.random()\n",
        "    )\n",
        "\n",
        "def decode_and_evaluate(chrom: Chromosome,\n",
        "                       feature_matrix: np.ndarray,\n",
        "                       close_prices: np.ndarray,\n",
        "                       side: int,\n",
        "                       cfg: Config) -> Tuple[float, int, float, float]:\n",
        "    \"\"\"\n",
        "    Decodes chromosome -> Calculates Thresholds -> Signals -> Backtest -> Score (0-100)\n",
        "    \"\"\"\n",
        "    # 1. Decode Thresholds\n",
        "    actual_thresholds = np.zeros(cfg.max_conditions, dtype=np.float64)\n",
        "    for k in range(cfg.max_conditions):\n",
        "        if chrom.active_conds[k]:\n",
        "            col_data = feature_matrix[:, chrom.feature_idxs[k]]\n",
        "            actual_thresholds[k] = np.nanquantile(col_data, chrom.threshold_quantiles[k])\n",
        "\n",
        "    # 2. Generate Signals\n",
        "    signals, n_active = calculate_signals_numba(\n",
        "        len(close_prices), cfg.max_conditions,\n",
        "        chrom.active_conds, chrom.feature_idxs, chrom.operators,\n",
        "        actual_thresholds, feature_matrix\n",
        "    )\n",
        "\n",
        "    if n_active == 0 or np.sum(signals) < 5: # Minimum valid trades to even score\n",
        "        return 0.0, 0, 0.0, cfg.initial_capital\n",
        "\n",
        "    # 3. Backtest\n",
        "    sl_pct = cfg.sl_min + chrom.sl_gene * (cfg.sl_max - cfg.sl_min)\n",
        "    wins, losses, end_equity = backtest_numba(\n",
        "        close_prices, signals, side, sl_pct, cfg.reward_risk_ratio,\n",
        "        cfg.initial_capital, cfg.risk_per_trade, cfg.commission\n",
        "    )\n",
        "\n",
        "    total_trades = wins + losses\n",
        "    if total_trades < cfg.min_trades:\n",
        "        # Penalize drastically if trades are insufficient but don't zero out if close\n",
        "        return 0.0, total_trades, 0.0, end_equity\n",
        "\n",
        "    net_profit = end_equity - cfg.initial_capital\n",
        "    win_rate = wins / total_trades if total_trades > 0 else 0\n",
        "\n",
        "    # 4. SCORING FUNCTION (Normalized 0-100)\n",
        "    # Weights: 40% WinRate, 40% Profitability, 20% Activity\n",
        "\n",
        "    # A. Win Rate Score (0 to 40)\n",
        "    score_wr = win_rate * 40.0\n",
        "\n",
        "    # B. Profit Score (0 to 40) - Capped at 100% ROI\n",
        "    roi = net_profit / cfg.initial_capital\n",
        "    score_profit = min(max(roi, 0.0), 1.0) * 40.0\n",
        "\n",
        "    # C. Activity Score (0 to 20) - Capped at 100 trades\n",
        "    score_activity = min(total_trades / 100.0, 1.0) * 20.0\n",
        "\n",
        "    # Total Score\n",
        "    final_score = score_wr + score_profit + score_activity\n",
        "\n",
        "    # Severe penalty for negative profit\n",
        "    if net_profit <= 0:\n",
        "        final_score = final_score * 0.1 # Keep it low\n",
        "\n",
        "    return final_score, total_trades, win_rate, end_equity\n",
        "\n",
        "# ==========================================\n",
        "# MODIFIED GA LOGIC (Clean Output)\n",
        "# ==========================================\n",
        "import copy\n",
        "\n",
        "def evolve_population(df: pd.DataFrame,\n",
        "                     side: int,\n",
        "                     cfg: Config,\n",
        "                     verbose: bool = False,\n",
        "                     initial_population: List[Chromosome] = None) -> Tuple[Chromosome, List[str], List[Chromosome]]:\n",
        "    \"\"\"\n",
        "    Runs GA. If initial_population is provided, it continues evolution from there.\n",
        "    Returns: Best Chromosome, Feature Names, and the FINAL POPULATION.\n",
        "    \"\"\"\n",
        "    feature_cols = [c for c in df.columns if c != 'close']\n",
        "    feature_matrix = df[feature_cols].values.astype(np.float64)\n",
        "    close_prices = df['close'].values.astype(np.float64)\n",
        "    n_features = len(feature_cols)\n",
        "\n",
        "    # --- 1. Load previous population if available ---\n",
        "    if initial_population is not None:\n",
        "        if verbose: print(f\"   >> Loaded {len(initial_population)} strategies from previous window...\")\n",
        "        population = [copy.deepcopy(c) for c in initial_population]\n",
        "\n",
        "        while len(population) < cfg.pop_size:\n",
        "            population.append(create_random_chromosome(n_features, cfg))\n",
        "        population = population[:cfg.pop_size]\n",
        "    else:\n",
        "        population = [create_random_chromosome(n_features, cfg) for _ in range(cfg.pop_size)]\n",
        "\n",
        "    best_chrom = None\n",
        "    best_score = -1.0\n",
        "\n",
        "    # REMOVED: Table Header Print\n",
        "    # if verbose:\n",
        "    #     print(f\"{'Gen':<5} {'Score':<10} {'Profit ($)':<12} {'Trades':<8} {'WinRate':<8}\")\n",
        "    #     print(\"-\" * 50)\n",
        "\n",
        "    for gen in range(cfg.n_generations):\n",
        "        scores = []\n",
        "        gen_best_score = -1\n",
        "        # gen_best_stats = (0, 0, 0) # No longer needed for printing\n",
        "\n",
        "        # Evaluation\n",
        "        for chrom in population:\n",
        "            score, tr, wr, eq = decode_and_evaluate(chrom, feature_matrix, close_prices, side, cfg)\n",
        "            scores.append(score)\n",
        "\n",
        "            # Global Best\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_chrom = copy.deepcopy(chrom)\n",
        "\n",
        "            # Generation Best (Logic kept for internal tracking, but printing removed)\n",
        "            if score > gen_best_score:\n",
        "                gen_best_score = score\n",
        "                # gen_best_stats = (eq - cfg.initial_capital, tr, wr)\n",
        "\n",
        "        # REMOVED: Table Row Print\n",
        "        # if verbose and (gen % 10 == 0 or gen == cfg.n_generations - 1):\n",
        "        #      profit, tr, wr = gen_best_stats\n",
        "        #      print(f\"{gen:<5} {gen_best_score:<10.1f} {profit:<12.2f} {tr:<8} {wr*100:<7.1f}%\")\n",
        "\n",
        "        # Selection & Mutation (Standard GA)\n",
        "        next_pop = [best_chrom] # Elitism\n",
        "\n",
        "        while len(next_pop) < cfg.pop_size:\n",
        "            p1, p2 = random.sample(range(cfg.pop_size), 2)\n",
        "            parent = population[p1] if scores[p1] > scores[p2] else population[p2]\n",
        "\n",
        "            child = copy.deepcopy(parent)\n",
        "\n",
        "            if random.random() < cfg.mutation_rate:\n",
        "                child.active_conds[random.randint(0, cfg.max_conditions - 1)] = 1 - child.active_conds[random.randint(0, cfg.max_conditions - 1)]\n",
        "            if random.random() < cfg.mutation_rate:\n",
        "                child.feature_idxs[random.randint(0, cfg.max_conditions - 1)] = random.randint(0, n_features - 1)\n",
        "            if random.random() < cfg.mutation_rate:\n",
        "                idx = random.randint(0, cfg.max_conditions - 1)\n",
        "                child.threshold_quantiles[idx] = np.clip(child.threshold_quantiles[idx] + np.random.normal(0, 0.1), 0.05, 0.95)\n",
        "\n",
        "            next_pop.append(child)\n",
        "\n",
        "        population = next_pop\n",
        "\n",
        "    return best_chrom, feature_cols, population"
      ],
      "metadata": {
        "id": "3BwzaSJN0ey6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. WALK-FORWARD ANALYSIS (EXPANDING WINDOW)\n",
        "# ==========================================\n",
        "# ==========================================\n",
        "# MODIFIED WFA (Passes Population Forward)\n",
        "# ==========================================\n",
        "def run_walk_forward_optimization(df: pd.DataFrame,\n",
        "                                side: int,\n",
        "                                cfg: Config) -> Tuple[List[Dict], List[float]]:\n",
        "    \"\"\"\n",
        "    Performs Anchored Walk-Forward Analysis with Population Persistence.\n",
        "    0-15k -> Train -> Test 15-30k ->\n",
        "    0-30k -> Train (Start with Pop from 0-15k) -> Test 30-45k -> ...\n",
        "    \"\"\"\n",
        "    n_rows = len(df)\n",
        "    current_split = cfg.train_window\n",
        "\n",
        "    oos_trades = []\n",
        "    equity_curve = [cfg.initial_capital]\n",
        "    running_capital = cfg.initial_capital\n",
        "\n",
        "    # --- STATE VARIABLE FOR POPULATION ---\n",
        "    current_population = None\n",
        "\n",
        "    side_name = \"LONG\" if side == 1 else \"SHORT\"\n",
        "    print(f\"\\nðŸš€ Starting PERSISTENT Walk-Forward for {side_name}\")\n",
        "    print(f\"   Initial Train Size: {cfg.train_window} | Test Step: {cfg.test_window}\")\n",
        "\n",
        "    window_count = 0\n",
        "\n",
        "    while current_split + cfg.test_window <= n_rows:\n",
        "        window_count += 1\n",
        "\n",
        "        # 1. Define Windows\n",
        "        train_start = 0\n",
        "        train_end = current_split\n",
        "        test_start = current_split\n",
        "        test_end = current_split + cfg.test_window\n",
        "\n",
        "        df_train = df.iloc[train_start:train_end].copy()\n",
        "        df_test = df.iloc[test_start:test_end].copy()\n",
        "\n",
        "        # 2. Optimize (Transferring Knowledge)\n",
        "        print(f\"\\nðŸ”„ Training Window {window_count}: Rows 0 to {train_end}\")\n",
        "        if current_population is not None:\n",
        "             print(f\"   >> Injecting {len(current_population)} strategies from previous window...\")\n",
        "\n",
        "        # --- CALL GENETIC ALGORITHM WITH PREVIOUS POPULATION ---\n",
        "        best_chrom, feats, end_population = evolve_population(\n",
        "            df_train, side, cfg, verbose=False, initial_population=current_population\n",
        "        )\n",
        "\n",
        "        # Save population for the NEXT larger window\n",
        "        current_population = end_population\n",
        "\n",
        "        # 3. Reporting & Testing (Standard Logic)\n",
        "        feature_matrix_train = df_train[feats].values.astype(np.float64)\n",
        "        score_train, tr_train, wr_train, eq_train = decode_and_evaluate(\n",
        "            best_chrom, feature_matrix_train, df_train['close'].values.astype(np.float64), side, cfg\n",
        "        )\n",
        "\n",
        "        sl_pct = cfg.sl_min + best_chrom.sl_gene * (cfg.sl_max - cfg.sl_min)\n",
        "\n",
        "        # Validation on OOS\n",
        "        feature_matrix_test = df_test[feats].values.astype(np.float64)\n",
        "        actual_thresholds = np.zeros(cfg.max_conditions)\n",
        "        for k in range(cfg.max_conditions):\n",
        "            if best_chrom.active_conds[k]:\n",
        "                idx = best_chrom.feature_idxs[k]\n",
        "                actual_thresholds[k] = np.nanquantile(feature_matrix_train[:, idx], best_chrom.threshold_quantiles[k])\n",
        "\n",
        "        signals_test, _ = calculate_signals_numba(\n",
        "            len(df_test), cfg.max_conditions,\n",
        "            best_chrom.active_conds, best_chrom.feature_idxs, best_chrom.operators,\n",
        "            actual_thresholds, feature_matrix_test\n",
        "        )\n",
        "\n",
        "        wins, losses, segment_end_eq = backtest_numba(\n",
        "            df_test['close'].values.astype(np.float64), signals_test, side, sl_pct, cfg.reward_risk_ratio,\n",
        "            cfg.initial_capital, cfg.risk_per_trade, cfg.commission\n",
        "        )\n",
        "\n",
        "        segment_profit = segment_end_eq - cfg.initial_capital\n",
        "        running_capital += segment_profit\n",
        "        equity_curve.append(running_capital)\n",
        "\n",
        "        print(f\"   ðŸ§ª OOS Result: Profit ${segment_profit:.2f} | WR: {(wins/(wins+losses)*100) if (wins+losses)>0 else 0:.1f}%\")\n",
        "\n",
        "        oos_trades.append({\n",
        "            'window': window_count,\n",
        "            'profit': segment_profit,\n",
        "            'equity': running_capital\n",
        "        })\n",
        "\n",
        "        current_split += cfg.test_window\n",
        "\n",
        "    return oos_trades, equity_curve"
      ],
      "metadata": {
        "id": "-nsZHX0Z1ahG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. DATA UTILS & REPORTING\n",
        "# ==========================================\n",
        "def load_data(filepath: str) -> pd.DataFrame:\n",
        "    print(f\"Loading {filepath}...\")\n",
        "    df = pd.read_csv(filepath, parse_dates=True, index_col=0)\n",
        "    df.columns = [c.lower() for c in df.columns]\n",
        "\n",
        "    # Cleaning\n",
        "    drops = ['open', 'high', 'low', 'volume']\n",
        "    existing_drops = [c for c in drops if c in df.columns and c != 'close']\n",
        "    df.drop(columns=existing_drops, inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    # Cast to float32/64\n",
        "    for col in df.columns:\n",
        "        df[col] = df[col].astype(np.float32)\n",
        "\n",
        "    return df\n",
        "\n",
        "def align_datasets(df_train: pd.DataFrame, df_test: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Ensures test set has exact same columns as train set.\"\"\"\n",
        "    feature_cols = [c for c in df_train.columns if c != 'close']\n",
        "    for c in feature_cols:\n",
        "        if c not in df_test.columns:\n",
        "            df_test[c] = 0.0\n",
        "    return df_test[feature_cols + ['close']].copy()\n",
        "\n",
        "def print_strategy_report(title: str, chrom: Chromosome, feats: List[str],\n",
        "                         train_matrix: np.ndarray, sl_pct: float, rr: float):\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"ðŸ“œ {title}\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Risk Settings: SL {sl_pct*100:.2f}% | TP {sl_pct*rr*100:.2f}%\")\n",
        "    print(\"Entry Conditions:\")\n",
        "\n",
        "    for k in range(len(chrom.active_conds)):\n",
        "        if chrom.active_conds[k]:\n",
        "            idx = chrom.feature_idxs[k]\n",
        "            # Decode threshold value for display\n",
        "            val = np.nanquantile(train_matrix[:, idx], chrom.threshold_quantiles[k])\n",
        "            op = \">\" if chrom.operators[k] == 1 else \"<\"\n",
        "            print(f\"  â€¢ {feats[idx]} {op} {val:.5f} (q={chrom.threshold_quantiles[k]:.2f})\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "1gF2vg_o0u_M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 6. MAIN EXECUTION (FULL EXPANDING LOGIC)\n",
        "# ==========================================\n",
        "\n",
        "def run_full_analysis(side_name: str, side_val: int, df_train, df_test, cfg):\n",
        "    print(f\"\\n\" + \"â–ˆ\"*60)\n",
        "    print(f\"   STARTING ANALYSIS FOR: {side_name} (Side={side_val})\")\n",
        "    print(\"â–ˆ\"*60)\n",
        "\n",
        "    # --- PART A: Walk-Forward Analysis ---\n",
        "    # Using the new Expanding Window function\n",
        "    print(f\"\\nðŸ“Š Phase 1: Expanding Walk-Forward Analysis...\")\n",
        "    logs, equity_curve = run_walk_forward_optimization(df_train, side_val, cfg)\n",
        "\n",
        "    wfa_profit = equity_curve[-1] - cfg.initial_capital\n",
        "    print(f\"\\n   >> Cumulative WFA Profit: ${wfa_profit:.2f}\")\n",
        "\n",
        "    # --- PART B: Final Training ---\n",
        "    print(f\"\\nðŸ”¬ Phase 2: Final Training (Using ALL Training Data)...\")\n",
        "    # For Expanding Window strategy, we train on the FULL dataset before hitting the Held-Out test\n",
        "    # Previously we sliced [-window:], now we use everything.\n",
        "    df_full_train = df_train.copy()\n",
        "\n",
        "    # We show the progress table here only (verbose=True) as requested\n",
        "    best_chrom, feats = evolve_population(df_full_train, side_val, cfg, verbose=True)\n",
        "\n",
        "    # Decode Final Stats\n",
        "    sl_pct = cfg.sl_min + best_chrom.sl_gene * (cfg.sl_max - cfg.sl_min)\n",
        "    tp_pct = sl_pct * cfg.reward_risk_ratio\n",
        "\n",
        "    # --- PART C: Held-Out Test ---\n",
        "    print(f\"\\nðŸ§ª Phase 3: Testing on Held-Out Data...\")\n",
        "\n",
        "    # Prepare Test Data\n",
        "    feature_matrix_test = df_test[feats].values.astype(np.float64)\n",
        "    close_test = df_test['close'].values.astype(np.float64)\n",
        "    feature_matrix_train = df_full_train[feats].values.astype(np.float64)\n",
        "\n",
        "    # Decode Thresholds\n",
        "    actual_thresholds = np.zeros(cfg.max_conditions)\n",
        "    print(\"\\nðŸ“œ SELECTED RULES (From Full Training Data):\")\n",
        "    for k in range(cfg.max_conditions):\n",
        "        if best_chrom.active_conds[k]:\n",
        "            idx = best_chrom.feature_idxs[k]\n",
        "            val = np.nanquantile(feature_matrix_train[:, idx], best_chrom.threshold_quantiles[k])\n",
        "            actual_thresholds[k] = val\n",
        "            op = \">\" if best_chrom.operators[k] == 1 else \"<\"\n",
        "            print(f\"   â€¢ {feats[idx]} {op} {val:.5f}\")\n",
        "\n",
        "    # Backtest\n",
        "    signals_final, _ = calculate_signals_numba(\n",
        "        len(df_test), cfg.max_conditions,\n",
        "        best_chrom.active_conds, best_chrom.feature_idxs, best_chrom.operators,\n",
        "        actual_thresholds, feature_matrix_test\n",
        "    )\n",
        "\n",
        "    wins, losses, end_equity = backtest_numba(\n",
        "        close_test, signals_final, side_val, sl_pct, cfg.reward_risk_ratio,\n",
        "        cfg.initial_capital, cfg.risk_per_trade, cfg.commission\n",
        "    )\n",
        "\n",
        "    trades = wins + losses\n",
        "    wr = (wins / trades) * 100 if trades > 0 else 0.0\n",
        "    net_profit = end_equity - cfg.initial_capital\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"ðŸ FINAL HELD-OUT RESULT ({side_name}):\")\n",
        "    print(f\"   Net Profit:        ${net_profit:.2f}\")\n",
        "    print(f\"   Trades:            {trades}\")\n",
        "    print(f\"   Win Rate:          {wr:.2f}%\")\n",
        "    print(f\"   Risk Settings:     SL={sl_pct*100:.2f}% | TP={tp_pct*100:.2f}%\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    return net_profit"
      ],
      "metadata": {
        "id": "dwLpzArl07Rn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        drive.mount('/content/drive/')\n",
        "    except: pass\n",
        "\n",
        "    # Paths\n",
        "    TRAIN_PATH = \"/content/drive/MyDrive/Heuristics_Project/Phase 2/eth_5m_with_features.csv\"\n",
        "    TEST_PATH  = \"/content/drive/MyDrive/Heuristics_Project/Phase 2/eth_5m_with_features_test.csv\"\n",
        "\n",
        "    try:\n",
        "        df_train_full = load_data(TRAIN_PATH)\n",
        "        df_test_heldout = load_data(TEST_PATH)\n",
        "        df_test_heldout = align_datasets(df_train_full, df_test_heldout)\n",
        "        cfg = Config()\n",
        "\n",
        "        # Run Long\n",
        "        profit_long = run_full_analysis(\"LONG (BUY)\", 1, df_train_full, df_test_heldout, cfg)\n",
        "\n",
        "        # Run Short\n",
        "        profit_short = run_full_analysis(\"SHORT (SELL)\", -1, df_train_full, df_test_heldout, cfg)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPjGMDolez4l",
        "outputId": "25ad54dc-e534-4779-a370-e849ac38af1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Loading /content/drive/MyDrive/Heuristics_Project/Phase 2/eth_5m_with_features.csv...\n",
            "Loading /content/drive/MyDrive/Heuristics_Project/Phase 2/eth_5m_with_features_test.csv...\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "   STARTING ANALYSIS FOR: LONG (BUY) (Side=1)\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\n",
            "ðŸ“Š Phase 1: Expanding Walk-Forward Analysis...\n",
            "\n",
            "ðŸš€ Starting PERSISTENT Walk-Forward for LONG\n",
            "   Initial Train Size: 15000 | Test Step: 15000\n",
            "\n",
            "ðŸ”„ Training Window 1: Rows 0 to 15000\n",
            "   ðŸ§ª OOS Result: Profit $0.00 | WR: 0.0%\n",
            "\n",
            "ðŸ”„ Training Window 2: Rows 0 to 30000\n",
            "   >> Injecting 100 strategies from previous window...\n",
            "   ðŸ§ª OOS Result: Profit $-132.24 | WR: 32.7%\n",
            "\n",
            "   >> Cumulative WFA Profit: $-132.24\n",
            "\n",
            "ðŸ”¬ Phase 2: Final Training (Using ALL Training Data)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9RpN8sH5kT6h"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}